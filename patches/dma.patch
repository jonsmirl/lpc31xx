Bottom: d5303dceb1375b14e2c0dfe5025cc2b5c655c126
Top:    3e81524a86a3dd4542d88f9296bc2b165b09ef79
Author: Jon Smirl <jonsmirl@gmail.com>
Date:   2012-06-16 22:11:56 -0400

DMA rework


---

diff --git a/arch/arm/boot/dts/ea3131.dts b/arch/arm/boot/dts/ea3131.dts
index a8ff332..d1eb9d4 100644
--- a/arch/arm/boot/dts/ea3131.dts
+++ b/arch/arm/boot/dts/ea3131.dts
@@ -16,6 +16,18 @@
 		bootargs = "console=ttyS0,115200n8 root=/dev/mmcblk0p3 init=/etc/preinit rw rootwait loglevel=7";
 	};
 
+	evtr@13000000 {
+		events = <
+			0 0x67 3 /* irq 0 EVT_wdog_m0, EVT_RISING_EDGE */
+			0 0x7A 2 /* irq 1 EVT_usb_otg_vbus_pwr_en, EVT_FALLING_EDGE */
+			0 0x77 2 /* irq 2 EVT_USB_VBUS, EVT_FALLING_EDGE */
+			0 0x7b 0 /* irq 3 EVT_USB_ID, EVT_ACTIVE_LOW */
+			1 0x18 1 /* irq 4 EVT_mNAND_RYBN3, EVT_ACTIVE_HIGH, DM9000_ETH_INT */
+			2 0x50 0 /* irq 5 EVT_mI2STX_BCK0, EVT_ACTIVE_LOW, SDMMC_CD */
+			3 0x55 0 /* irq 6 EVT_I2SRX_WS0, EVT_ACTIVE_LOW, EA_VBUS_OVRC */
+			3 0x33 1 /* irq 7 EVT_GPIO4, EVT_ACTIVE_HIGH, PENDOWN */
+		>;
+	};
 	i2c@1300a000 {
 		slave-addr = <0x6E>;
 		pca9532: leds@60 {
@@ -33,22 +45,24 @@
 		};
 	};
 	spi@15002000 {
+		gpios = <&gpio_spi 4 0  /* chip selects */
+			 &gpio_ebi_i2stx_0 3 0>; 
 		s25sl032a@0 {
 			compatible = "code,s25sl032a";
-			spi-max-frequency = <1000000>;
 			reg = <0>;
+			spi-max-frequency = <1000000>;
 		};
 		ads7846@1 {
 			compatible = "ti,ads7846";
-			spi-max-frequency = <1200000>;
 			reg = <1>;
+			spi-max-frequency = <1200000>;
 			interrupts = <20>;
 			vref_delay_usecs = <100>;
-			x_plate_ohms = <419>;
-			y_plate_ohms = <486>;
-			pen_irq = <37>;
-			gpio_pendown = <&gpio_gpio 4 0>;
-			gpio_cs = <&gpio_ebi_i2stx_0 3 0>; 
+			x-plate-ohms = <419>;
+			y-plate-ohms = <486>;
+			interrupt-parent = <&evtr>;
+			pen-irq = <7 4>;
+			gpio-pendown = <&gpio_gpio 4 0>;
 		};
 	};
 	sound {
@@ -65,17 +79,19 @@
 		slot@0 {
 			width = <4>;
 			detect-delays = <250>;
-			gpio-cd = <&gpio_cgu 7 0>;
-			gpio-power = <&gpio_ebi_i2stx_0 5 0>;
-			/* gpio-power = <&gpio_ebi_i2stx_0 5 0>; broken in hardware */
-			/* gpio-wp = <>; not implemented in hardware */
-			/* gpio-select = <>; not implemented in hardware */
 			voltage-ranges = <3200 3400>;
+			gpios = <
+				&gpio_ebi_mci 7 0 /* card detect */
+				0 /* write protect, no hardware */
+				&gpio_ebi_i2stx_0 5 0 /* power, broken hardware design */
+				0 /* slot select, no hardware */
+			>;
+			interrupt-parent = <&evtr>;
+			interrupt = <6 8>;
 		};
 	};
 	usb@19000000 {
 		vbus-over =  <&gpio_i2srx_0 2 0>;
-		vbus-interrupts = <36>;
 	};
 	sram@20000000 {
 		mpmc-config = <0x81 0 0 31 0 3 0>;
@@ -85,12 +101,18 @@
 		};
 	};
 	sram@20020000 {
-		/* enable oe toggle between consec reads */
+		/* enable oe toggle between consecutive reads */
 		mpmc-config = <0x81 1 1 4 1 1 2 0x24>;
 		dm9000@20020000 {
 			compatible = "davicom,dm9000";
 			reg = <0x20020000 0x100 0x20030000 0x100>;
+			/* interrupt-parent = <&evtr>; 
+			interrupts = <4 4>; */
 			interrupts = <34>;
+			gpios = <
+				&gpio_ebi_i2stx_0 2 0 /* main irq, map gpio to irq */
+				0  /* WOL irq, map gpio to irq */
+			>;
 		};			
 	};
 	memory@30000000 {
diff --git a/arch/arm/boot/dts/lpc3131.dtsi b/arch/arm/boot/dts/lpc3131.dtsi
index 7768a40..096fe21 100644
--- a/arch/arm/boot/dts/lpc3131.dtsi
+++ b/arch/arm/boot/dts/lpc3131.dtsi
@@ -29,10 +29,14 @@
 		reg = <0x11040000 0x18000>;
 		interrupts = <29>;
 	};
-	evtr@13000000 {
+	evtr: evtr@13000000 {
+		#event-cells = <3>;
 		compatible = "nxp,lpc31xx-evtr";
+		interrupt-controller;
+		#interrupt-cells = <2>;
 		reg = <0x13000000 0x800>;
-		interrupts = <1 2 3 4>;
+		interrupt-parent = <&intc>;
+		interrupts = <1 2 3 4>;  /* cascaded */
 	};
 	adc@13002000 {
 		compatible = "nxp,lpc31xx-adc";
@@ -42,7 +46,8 @@
 	wdt@13002400 {
 		compatible = "nxp,lpc31xx-wdt";
 		reg = <0x13002400 0x400>;
-		interrupts = <30>;
+		interrupt-parent = <&evtr>;
+		interrupts = <0 1>;
 	};
 	sys@13002800 {
 		compatible = "nxp,lpc31xx-sys";
diff --git a/arch/arm/mach-lpc31xx/board-ea313x.c b/arch/arm/mach-lpc31xx/board-ea313x.c
index 76679ce..368f7e0 100644
--- a/arch/arm/mach-lpc31xx/board-ea313x.c
+++ b/arch/arm/mach-lpc31xx/board-ea313x.c
@@ -52,15 +52,15 @@
 
 
 /*
- * DM9000 ethernet device
+ * DM9000 Ethernet device
  */
 
-/* ARM MPMC contoller as part of low power design doesn't de-assert nCS and nOE for consecutive
+/* ARM MPMC controller as part of low power design doesn't de-assert nCS and nOE for consecutive
 reads but just changes address. But DM9000 requires nCS and nOE change between address. So access
 other chip select area (nCS0) to force de-assertion of nCS1 and nOE1. Or else wait for long time
 such as 80 usecs.
 LPC313x has external logic outside of MPMC IP to toggle nOE to split consecutive reads.
-The latest Apex bootloader pacth makes use of this feture.
+The latest Apex bootloader patch makes use of this feature.
 For this to work SYS_MPMC_WTD_DEL0 & SYS_MPMC_WTD_DEL1 should be programmed with MPMC_STWTRD0
 & MPMC_STWTRD1 values. The logic only deactivates the nOE for one clock cycle which is
 11nsec but DM9000 needs 80nsec between nOEs. So lets add some dummy instructions such as
@@ -97,62 +97,6 @@ static struct dm9000_plat_data dm9000_platdata = {
 	.inblk = dm9000_inblk,
 };
 
-
-/* spi_board_info.controller_data for SPI slave devices,
- * copied to spi_device.platform_data ... mostly for dma tuning
- */
-struct lpc313x_spi_chip {
-	u8 tx_threshold;
-	u8 rx_threshold;
-	u8 dma_burst_size;
-	u32 timeout;
-	u8 enable_loopback;
-	int gpio_cs;
-	void (*cs_control)(u32 command);
-};
-
-static struct ads7846_platform_data ea313x_ads7846_info = {
-	.model			= 7846,
-	.vref_delay_usecs	= 100,
-	.x_plate_ohms		= 419,
-	.y_plate_ohms		= 486,
-	.gpio_pendown		= GPIO_GPIO4,
-};
-
-static struct lpc313x_spi_chip ea313x_ads7846_chip = {
-	.gpio_cs	= GPIO_MUART_CTS_N,
-};
-
-/* If both SPIDEV and MTD data flash are enabled with the same chip select, only 1 will work */
-#if defined(CONFIG_SPI_SPIDEV)
-/* SPIDEV driver registration */
-static int __init lpc313x_spidev_register(void)
-{
-	struct spi_board_info info[] = {
-	{
-		.modalias = "spidev",
-		.max_speed_hz = 1000000,
-		.bus_num = 0,
-		.chip_select = 0,
-	}, {
-		.modalias	= "ads7846",
-		.max_speed_hz	= 1200000,
-		.bus_num	= 0,
-		.chip_select	= 1,
-		.platform_data	= &ea313x_ads7846_info,
-		.controller_data= &ea313x_ads7846_chip,
-		.irq		= IRQ_PENDOWN,
-	}};
-	gpio_request(GPIO_MUART_CTS_N, "touchscreen CS");
-	gpio_direction_output(GPIO_MUART_CTS_N, 1);
-
-	return spi_register_board_info(info, 3);
-}
-//arch_initcall(lpc313x_spidev_register);
-#endif
-
-
-
 #if defined(CONFIG_MACH_EA3152)
 static struct i2c_board_info ea3152_i2c1_devices[] __initdata = {
 	{
diff --git a/arch/arm/mach-lpc31xx/dma.c b/arch/arm/mach-lpc31xx/dma.c
index bf6e040..62e2ca0 100644
--- a/arch/arm/mach-lpc31xx/dma.c
+++ b/arch/arm/mach-lpc31xx/dma.c
@@ -35,7 +35,7 @@
 #include <mach/clock.h>
 #include <mach/dma.h>
 
-
+#ifdef LPDMA
 static spinlock_t driver_lock; /* to guard state variables */
 
 static inline void lpc313x_dma_lock(void)
@@ -103,7 +103,7 @@ int dma_prog_channel (unsigned int chn, dma_setup_t *dma_setup)
 	return 0;
 }
 
-int dma_request_channel (char *name, dma_cb_t cb, void *data)
+int dma_request_channel_x (char *name, dma_cb_t cb, void *data)
 {
 	unsigned int mask;
 	unsigned int chn;
@@ -233,7 +233,7 @@ int dma_stop_channel_sg (unsigned int chn)
 	return 0;
 }
 
-int dma_release_channel (unsigned int chn)
+int dma_release_channel_x (unsigned int chn)
 {
 	unsigned int mask = (0x3 << (chn * 2));
 	unsigned long flags;
@@ -264,6 +264,7 @@ int dma_release_channel (unsigned int chn)
 	return 0;
 }
 
+#if 0
 static irqreturn_t dma_irq_handler (int irq, void *dev_id)
 {
 	unsigned int mask;
@@ -312,6 +313,7 @@ static irqreturn_t dma_irq_handler (int irq, void *dev_id)
 
 	return IRQ_HANDLED;
 }
+#endif
 
 int dma_read_counter (unsigned int chn, unsigned int * pcnt)
 {
@@ -484,6 +486,7 @@ int dma_channel_enabled(unsigned int chn)
 	return (DMACH_EN(chn) & 1);
 }
 
+#if 0
 static int __init lpc313x_dma_init (void)
 {
 	int ret = 0;
@@ -499,6 +502,7 @@ static int __init lpc313x_dma_init (void)
 
 	return ret;
 }
+#endif
 
 int dma_release_sg_channel (unsigned int chn)
 {
@@ -539,23 +543,44 @@ int dma_prepare_sg_list(int n, dma_sg_ll_t * sg)
     /* fixed me: not yet implement */
     return 0;
 }
+#else
+int dma_request_channel_x (char *name, dma_cb_t cb, void *data){return 0;}
+int dma_request_specific_channel (int chn, char *name, void (*cb)(int, dma_irq_type_t, void *), void *data){return 0;}
+int dma_request_sg_channel (char *name, dma_cb_t cb, void *data, dma_cb_t cb1, void *data1, int usesoftirq){return 0;}
+int dma_request_specific_sg_channel (int chn, char *name, dma_cb_t cb, void *data, dma_cb_t cb1, void *data1, int usesoftirq){return 0;}
+int dma_release_channel_x (unsigned int chn){return 0;}
+int dma_release_sg_channel (unsigned int chn){return 0;}
+int dma_prog_channel (unsigned int chn, dma_setup_t *dma_setup){return 0;}
+int dma_start_channel (unsigned int chn){return 0;}
+int dma_stop_channel (unsigned int chn){return 0;}
+int dma_prog_sg_channel(int chn, u32 dma_sg_list){return 0;}
+int dma_set_irq_mask(unsigned int chn, int half_int, int fin_int){return 0;}
+int dma_write_counter (unsigned int chn, u32 cnt){return 0;}
+int dma_stop_channel_sg (unsigned int chn){return 0;}
+int dma_channel_enabled(unsigned int chn){return 0;}
+int dma_current_state (unsigned int   chn, unsigned int * psrc, unsigned int * pdst, unsigned int * plen, unsigned int * pcfg, unsigned int * pena, unsigned int * pcnt){return 0;}
+int dma_read_counter (unsigned int chn, unsigned int * pcnt){return 0;}
+int dma_prepare_sg_list(int n, dma_sg_ll_t * sg){return 0;}
+#endif
+
+//device_initcall(lpc313x_dma_init);
+
+EXPORT_SYMBOL(dma_request_channel_x);
+EXPORT_SYMBOL(dma_request_specific_channel);
+EXPORT_SYMBOL(dma_request_sg_channel);
+EXPORT_SYMBOL(dma_request_specific_sg_channel);
 
-device_initcall(lpc313x_dma_init);
+EXPORT_SYMBOL(dma_release_channel_x);
+EXPORT_SYMBOL(dma_release_sg_channel);
 
 
 EXPORT_SYMBOL(dma_prog_channel);
-EXPORT_SYMBOL(dma_request_channel);
-EXPORT_SYMBOL(dma_request_specific_channel);
 EXPORT_SYMBOL(dma_start_channel);
 EXPORT_SYMBOL(dma_stop_channel);
-EXPORT_SYMBOL(dma_release_channel);
 EXPORT_SYMBOL(dma_set_irq_mask);
 EXPORT_SYMBOL(dma_read_counter);
 EXPORT_SYMBOL(dma_write_counter);
 EXPORT_SYMBOL(dma_current_state);
-EXPORT_SYMBOL(dma_request_sg_channel);
-EXPORT_SYMBOL(dma_request_specific_sg_channel);
 EXPORT_SYMBOL(dma_prog_sg_channel);
-EXPORT_SYMBOL(dma_release_sg_channel);
 EXPORT_SYMBOL(dma_prepare_sg_list);
 EXPORT_SYMBOL(dma_channel_enabled);
diff --git a/arch/arm/mach-lpc31xx/generic.c b/arch/arm/mach-lpc31xx/generic.c
index 9765b48..9fce256 100644
--- a/arch/arm/mach-lpc31xx/generic.c
+++ b/arch/arm/mach-lpc31xx/generic.c
@@ -213,6 +213,8 @@ void __init lpc313x_init(void)
 	/* Disable ring oscillators used by Random number generators */
 	SYS_RNG_OSC_CFG = 0;
 
+#if 0
+	/* fix me */
 	/* Mux I2S signals based on selected channel */
 #if defined (CONFIG_SND_I2S_TX0_MASTER)
 	/* I2S TX0 WS, DATA */
@@ -237,7 +239,7 @@ void __init lpc313x_init(void)
 #endif
 	/* AUDIO CODEC CLOCK (256FS) */
 	GPIO_DRV_IP(IOCONF_I2STX_1, 0x8);
-
+#endif
 	lpc313x_uart_init();
 
 	return platform_add_devices(devices, ARRAY_SIZE(devices));
diff --git a/arch/arm/mach-lpc31xx/include/mach/dma.h b/arch/arm/mach-lpc31xx/include/mach/dma.h
index a5cc411..0e06a68 100644
--- a/arch/arm/mach-lpc31xx/include/mach/dma.h
+++ b/arch/arm/mach-lpc31xx/include/mach/dma.h
@@ -24,6 +24,7 @@
 #ifndef __ASM_ARCH_DMA_H
 #define __ASM_ARCH_DMA_H
 
+#include <linux/dmaengine.h>
 #include <mach/constants.h>
 
 /***********************************************************************
@@ -186,7 +187,7 @@ int dma_prog_channel (unsigned int, dma_setup_t   *);
  *
  * Returns: channel number on success, otherwise (negative) failure
  */
-int dma_request_channel (char *, dma_cb_t cb, void *);
+int dma_request_channel_x (char *, dma_cb_t cb, void *);
 
 /*
  * Request specific SDMA channel
@@ -245,7 +246,7 @@ int dma_stop_channel (unsigned int);
  *
  * Returns: 0 on success, otherwise failure
  */
-int dma_release_channel (unsigned int);
+int dma_release_channel_x (unsigned int);
 
 /*
  * Read channel counter
@@ -389,4 +390,23 @@ int dma_release_sg_channel (unsigned int);
  */
 int dma_channel_enabled(unsigned int);
 
+
+/**
+ * struct lpc31xx_dma_data - configuration data for the LPC31xx dmaengine
+ * @port: peripheral which is requesting the channel
+ * @direction: TX/RX channel
+ * @name: optional name for the channel, this is displayed in /proc/interrupts
+ *
+ * This information is passed as private channel parameter in a filter
+ * function. Note that this is only needed for slave/cyclic channels.  For
+ * memcpy channels %NULL data should be passed.
+ */
+struct lpc31xx_dma_data {
+	int port;
+	enum dma_transfer_direction	direction;
+	const char *name;
+};
+
+
+
 #endif				/* _ASM_ARCH_DMA_H */
diff --git a/arch/arm/mach-lpc31xx/include/mach/gpio.h b/arch/arm/mach-lpc31xx/include/mach/gpio.h
index cc52ad5..2e3175c 100644
--- a/arch/arm/mach-lpc31xx/include/mach/gpio.h
+++ b/arch/arm/mach-lpc31xx/include/mach/gpio.h
@@ -143,24 +143,9 @@
                   
 #define GPIO_UART_RXD         (IOCONF_UART | 0)
 #define GPIO_UART_TXD         (IOCONF_UART | 1)
-                
-extern int lpc313x_gpio_direction_output(unsigned gpio, int value);
-
-static inline int lpc313x_gpio_direction_input(unsigned gpio)
-{
-	unsigned long flags;
-	int port = (gpio & GPIO_PORT_MASK);
-	int pin = 1 << (gpio & GPIO_PIN_MASK);
-
-	raw_local_irq_save(flags);
-
-	GPIO_M1_RESET(port) = pin; 
-	GPIO_M0_RESET(port) = pin;
-
-	raw_local_irq_restore(flags);
-	return 0;
-}
 
+                
+#if 0
 static inline int lpc313x_gpio_ip_driven(unsigned gpio)
 {
 	unsigned long flags;
@@ -175,31 +160,7 @@ static inline int lpc313x_gpio_ip_driven(unsigned gpio)
 	raw_local_irq_restore(flags);
 	return 0;
 }
-
-
-static inline int lpc313x_gpio_get_value(unsigned gpio)
-{
-	return (GPIO_STATE(gpio & GPIO_PORT_MASK) & (1 << (gpio & GPIO_PIN_MASK)));
-}
-
-static inline void lpc313x_gpio_set_value(unsigned gpio, int value)
-{
-	unsigned long flags;
-	int port = (gpio & GPIO_PORT_MASK);
-	int pin = 1 << (gpio & GPIO_PIN_MASK);
-
-	raw_local_irq_save(flags);
-
-	GPIO_M1_SET(port) = pin; 
-
-	if(value) {
-		GPIO_M0_SET(port) = pin;
-	} else {
-		GPIO_M0_RESET(port) = pin;
-	}
-
-	raw_local_irq_restore(flags);
-}
+#endif
 
 
 #ifdef CONFIG_GPIOLIB
diff --git a/arch/arm/mach-lpc31xx/include/mach/registers.h b/arch/arm/mach-lpc31xx/include/mach/registers.h
index 01f4114..0ec045a 100644
--- a/arch/arm/mach-lpc31xx/include/mach/registers.h
+++ b/arch/arm/mach-lpc31xx/include/mach/registers.h
@@ -126,6 +126,7 @@
 #define UART_ICR_REG      __REG (UART_PHYS + 0x24)
 #define UART_FDR_REG      __REG (UART_PHYS + 0x28)
 
+#if 0
 /***********************************************************************
  * SPI register definitions
  **********************************************************************/
@@ -213,6 +214,7 @@
 #define SPI_TO_INT                _BIT(1)
 #define SPI_OVR_INT               _BIT(0)
 #define SPI_ALL_INTS              (SPI_SMS_INT | SPI_TX_INT | SPI_RX_INT | SPI_TO_INT | SPI_OVR_INT)
+#endif
 
 /***********************************************************************
 * Audio Subsystem (ADSS) register definitions
@@ -313,6 +315,7 @@
 /***********************************************************************
  * GPIO register definitions
  **********************************************************************/
+#if 0
 #define GPIO_STATE(port)     __REG (GPIO_PHYS + (port) + 0x00)
 #define GPIO_STATE_M0(port)  __REG (GPIO_PHYS + (port) + 0x10)
 #define GPIO_M0_SET(port)    __REG (GPIO_PHYS + (port) + 0x14)
@@ -320,6 +323,7 @@
 #define GPIO_STATE_M1(port)  __REG (GPIO_PHYS + (port) + 0x20)
 #define GPIO_M1_SET(port)    __REG (GPIO_PHYS + (port) + 0x24)
 #define GPIO_M1_RESET(port)  __REG (GPIO_PHYS + (port) + 0x28)
+#endif
 
 #define GPIO_OUT_LOW(port, pin)  do { GPIO_M1_SET(port) = pin; GPIO_M0_RESET(port) = pin;} while(0)
 #define GPIO_OUT_HIGH(port, pin) do { GPIO_M1_SET(port) = pin; GPIO_M0_SET(port) = pin;} while(0)
diff --git a/arch/arm/mach-lpc31xx/irq.c b/arch/arm/mach-lpc31xx/irq.c
index 4ff6533..5dc8f90 100644
--- a/arch/arm/mach-lpc31xx/irq.c
+++ b/arch/arm/mach-lpc31xx/irq.c
@@ -274,7 +274,7 @@ void __init lpc313x_init_irq(void)
 
 		irq_set_chip(irq, &lpc313x_evtr_chip);
 		set_irq_flags(irq, IRQF_VALID);
-		/* configure the interrupt senstivity */
+		/* configure the interrupt sensitivity */
 		switch (irq_2_event[irq - IRQ_EVT_START].type) {
 			case EVT_ACTIVE_LOW:
 				EVRT_APR(bank) &= ~_BIT(bit_pos);
@@ -299,6 +299,7 @@ void __init lpc313x_init_irq(void)
 			case EVT_BOTH_EDGE:
 				EVRT_ATR(bank) |= _BIT(bit_pos);
 				irq_set_handler(irq, handle_edge_irq);
+				break;
 			default:
 				printk("Invalid Event type.\r\n");
 				break;
@@ -345,7 +346,7 @@ void __init lpc313x_init_irq(void)
 	irq_set_chained_handler (IRQ_EVT_ROUTER3, router3_handler);
 #endif
 
-	/* Set the priority treshold to 0, i.e. don't mask any interrupt */
+	/* Set the priority threshold to 0, i.e. don't mask any interrupt */
 	/* on the basis of priority level, for both targets (IRQ/FIQ)    */
 	INTC_IRQ_PRI_MASK = 0;
 	INTC_FIQ_PRI_MASK = 0;
diff --git a/drivers/dma/Kconfig b/drivers/dma/Kconfig
index aadeb5b..1224500 100644
--- a/drivers/dma/Kconfig
+++ b/drivers/dma/Kconfig
@@ -244,6 +244,13 @@ config MXS_DMA
 	  Support the MXS DMA engine. This engine including APBH-DMA
 	  and APBX-DMA is integrated into Freescale i.MX23/28 chips.
 
+config LPC31XX_DMA
+	bool "LPC31xx DMA support"
+	depends on ARCH_LPC31XX
+	select DMA_ENGINE
+	help
+	  Support the NXP LPC31xx DMA engine.
+
 config EP93XX_DMA
 	bool "Cirrus Logic EP93xx DMA support"
 	depends on ARCH_EP93XX
diff --git a/drivers/dma/Makefile b/drivers/dma/Makefile
index 86b795b..45d6e79 100644
--- a/drivers/dma/Makefile
+++ b/drivers/dma/Makefile
@@ -20,6 +20,7 @@ obj-$(CONFIG_AMCC_PPC440SPE_ADMA) += ppc4xx/
 obj-$(CONFIG_IMX_SDMA) += imx-sdma.o
 obj-$(CONFIG_IMX_DMA) += imx-dma.o
 obj-$(CONFIG_MXS_DMA) += mxs-dma.o
+obj-$(CONFIG_LPC31XX_DMA) += lpc31xx-dma.o
 obj-$(CONFIG_TIMB_DMA) += timb_dma.o
 obj-$(CONFIG_SIRF_DMA) += sirf-dma.o
 obj-$(CONFIG_STE_DMA40) += ste_dma40.o ste_dma40_ll.o
diff --git a/drivers/dma/dmaengine.c b/drivers/dma/dmaengine.c
index 2397f6f..8224ab9 100644
--- a/drivers/dma/dmaengine.c
+++ b/drivers/dma/dmaengine.c
@@ -45,6 +45,8 @@
  * See Documentation/dmaengine.txt for more details
  */
 
+#define DEBUG
+
 #include <linux/dma-mapping.h>
 #include <linux/init.h>
 #include <linux/module.h>
diff --git a/drivers/dma/lpc31xx-dma.c b/drivers/dma/lpc31xx-dma.c
new file mode 100644
index 0000000..326a03f
--- /dev/null
+++ b/drivers/dma/lpc31xx-dma.c
@@ -0,0 +1,1179 @@
+/*  arch/arm/mach-lpc313x/dma.c
+ *
+ *  Author:	Durgesh Pattamatta
+ *  Copyright (C) 2009 NXP semiconductors
+ *
+ *  DMA driver for machines with LPC313x and LPC315x SoCs.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ *
+ */
+
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/dmaengine.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/dma-mapping.h>
+
+#include <mach/dma.h>
+
+struct lpc31xx_dma_engine;
+
+/**
+ * struct lpc31xx_dma_desc - LPC31xx specific transaction descriptor
+ * @src_addr: source address of the transaction
+ * @dst_addr: destination address of the transaction
+ * @size: size of the transaction (in bytes)
+ * @complete: this descriptor is completed
+ * @txd: dmaengine API descriptor
+ * @tx_list: list of linked descriptors
+ * @node: link used for putting this into a channel queue
+ */
+struct lpc31xx_dma_desc {
+	uint32_t src_addr;
+	uint32_t dst_addr;
+	size_t size;
+	bool complete;
+	struct dma_async_tx_descriptor txd;
+	struct list_head tx_list;
+	struct list_head node;
+};
+#define DMA_MAX_CHAN_DESCRIPTORS 32
+
+/**
+ * struct lpc31xx_dma_chan - an LPC31xx DMA channel
+ * @chan: dmaengine API channel
+ * @number: number of the channel
+ * @edma: pointer to to the engine device
+ * @regs: memory mapped registers
+ * @tasklet: channel specific tasklet used for callbacks
+ * @lock: lock protecting the fields following
+ * @flags: flags for the channel
+ * @buffer: which buffer to use next (0/1)
+ * @last_completed: last completed cookie value
+ * @active: flattened chain of descriptors currently being processed
+ * @queue: pending descriptors which are handled next
+ * @free_list: list of free descriptors which can be used
+ * @runtime_addr: physical address currently used as dest/src (M2M only). This
+ *                is set via %DMA_SLAVE_CONFIG before slave operation is
+ *                prepared
+ * @runtime_ctrl: M2M runtime values for the control register.
+ *
+ * As LPC31xx DMA controller doesn't support real chained DMA descriptors we
+ * will have slightly different scheme here: @active points to a head of
+ * flattened DMA descriptor chain.
+ *
+ * @queue holds pending transactions. These are linked through the first
+ * descriptor in the chain. When a descriptor is moved to the @active queue,
+ * the first and chained descriptors are flattened into a single list.
+ *
+ * @chan.private holds pointer to &struct lpc31xx_dma_data which contains
+ * necessary channel configuration information. For memcpy channels this must
+ * be %NULL.
+ */
+struct lpc31xx_dma_chan {
+	struct dma_chan chan;
+	int number;
+	const struct lpc31xx_dma_engine	*edma;
+	void __iomem *regs;
+	struct tasklet_struct tasklet;
+	unsigned long flags;
+/* Channel is configured for cyclic transfers */
+#define LPC31xx_DMA_IS_CYCLIC 0
+
+	int buffer;
+	dma_cookie_t last_completed;
+	struct list_head active;
+	struct list_head queue;
+	struct list_head free_list;
+	uint32_t runtime_addr;
+	uint32_t runtime_ctrl;
+};
+
+/**
+ * struct lpc31xx_dma_engine - the LPC31xx DMA engine instance
+ * @dma_dev: holds the dmaengine device
+ * @channels: array of channels
+ */
+struct lpc31xx_dma_engine {
+	struct dma_device dma_dev;
+#define INTERRUPT_UNKNOWN 0
+#define INTERRUPT_DONE 1
+#define INTERRUPT_NEXT_BUFFER 2
+
+	struct lpc31xx_dma_chan	channels[DMA_MAX_CHANNELS];
+};
+
+static inline struct device *chan2dev(struct lpc31xx_dma_chan *edmac)
+{
+	return &edmac->chan.dev->device;
+}
+
+static struct lpc31xx_dma_chan *to_lpc31xx_dma_chan(struct dma_chan *chan)
+{
+	return container_of(chan, struct lpc31xx_dma_chan, chan);
+}
+
+static spinlock_t driver_lock; /* to guard state variables */
+
+static unsigned int dma_irq_mask = 0xFFFFFFFF;
+static int sg_higher_channel[12] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
+static int softirqmask[12] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0};
+static int softirqen = 0;
+
+static int dma_channels_requested = 0;
+
+static inline void lpc31xx_dma_increment_usage(void)
+{
+	if (!dma_channels_requested++) {
+		cgu_clk_en_dis(CGU_SB_DMA_CLK_GATED_ID, 1);
+		cgu_clk_en_dis(CGU_SB_DMA_PCLK_ID, 1);
+	}
+}
+static inline void lpc31xx_dma_decrement_usage(void)
+{
+	if (!--dma_channels_requested) {
+		cgu_clk_en_dis(CGU_SB_DMA_CLK_GATED_ID, 0);
+		cgu_clk_en_dis(CGU_SB_DMA_PCLK_ID, 0);
+	}
+}
+
+/**
+ * lpc31xx_dma_set_active - set new active descriptor chain
+ * @edmac: channel
+ * @desc: head of the new active descriptor chain
+ *
+ * Sets @desc to be the head of the new active descriptor chain. This is the
+ * chain which is processed next. The active list must be empty before calling
+ * this function.
+ *
+ * Called with @driver_lock held and interrupts disabled.
+ */
+static void lpc31xx_dma_set_active(struct lpc31xx_dma_chan *edmac,
+				  struct lpc31xx_dma_desc *desc)
+{
+	printk("jds - lpc31xx_dma_set_active\n");
+	BUG_ON(!list_empty(&edmac->active));
+
+	list_add_tail(&desc->node, &edmac->active);
+
+	/* Flatten the @desc->tx_list chain into @edmac->active list */
+	while (!list_empty(&desc->tx_list)) {
+		struct lpc31xx_dma_desc *d = list_first_entry(&desc->tx_list,
+			struct lpc31xx_dma_desc, node);
+
+		/*
+		 * We copy the callback parameters from the first descriptor
+		 * to all the chained descriptors. This way we can call the
+		 * callback without having to find out the first descriptor in
+		 * the chain. Useful for cyclic transfers.
+		 */
+		d->txd.callback = desc->txd.callback;
+		d->txd.callback_param = desc->txd.callback_param;
+
+		list_move_tail(&d->node, &edmac->active);
+	}
+}
+
+/* Called with @driver_lock held and interrupts disabled */
+static struct lpc31xx_dma_desc *
+lpc31xx_dma_get_active(struct lpc31xx_dma_chan *edmac)
+{
+	printk("jds - lpc31xx_dma_get_active\n");
+	if (list_empty(&edmac->active))
+		return NULL;
+
+	return list_first_entry(&edmac->active, struct lpc31xx_dma_desc, node);
+}
+
+/**
+ * lpc31xx_dma_advance_active - advances to the next active descriptor
+ * @edmac: channel
+ *
+ * Function advances active descriptor to the next in the @edmac->active and
+ * returns %true if we still have descriptors in the chain to process.
+ * Otherwise returns %false.
+ *
+ * When the channel is in cyclic mode always returns %true.
+ *
+ * Called with @driver_lock held and interrupts disabled.
+ */
+static bool lpc31xx_dma_advance_active(struct lpc31xx_dma_chan *edmac)
+{
+	struct lpc31xx_dma_desc *desc;
+
+	printk("jds - lpc31xx_dma_advance_active\n");
+	list_rotate_left(&edmac->active);
+
+	if (test_bit(LPC31xx_DMA_IS_CYCLIC, &edmac->flags))
+		return true;
+
+	desc = lpc31xx_dma_get_active(edmac);
+	if (!desc)
+		return false;
+
+	/*
+	 * If txd.cookie is set it means that we are back in the first
+	 * descriptor in the chain and hence done with it.
+	 */
+	return !desc->txd.cookie;
+}
+
+/*
+ * M2P DMA implementation
+ */
+
+static void m2p_set_control(struct lpc31xx_dma_chan *edmac, uint32_t control)
+{
+	printk("jds - m2p_set_control\n");
+#if 0
+	writel(control, edmac->regs + M2P_CONTROL);
+	/*
+	 * LPC31xx User's Guide states that we must perform a dummy read after
+	 * write to the control register.
+	 */
+	readl(edmac->regs + M2P_CONTROL);
+#endif
+}
+
+static int m2p_hw_setup(struct lpc31xx_dma_chan *edmac)
+{
+	struct lpc31xx_dma_data *data = edmac->chan.private;
+	uint32_t control;
+
+	printk("jds - m2p_hw_setup\n");
+#if 0
+	writel(data->port & 0xf, edmac->regs + M2P_PPALLOC);
+
+	control = M2P_CONTROL_CH_ERROR_INT | M2P_CONTROL_ICE
+		| M2P_CONTROL_ENABLE;
+	m2p_set_control(edmac, control);
+#endif
+	return 0;
+}
+
+static inline uint32_t m2p_channel_state(struct lpc31xx_dma_chan *edmac)
+{
+	printk("jds - m2p_channel_state\n");
+#if 0
+	return (readl(edmac->regs + M2P_STATUS) >> 4) & 0x3;
+#endif
+}
+
+static void m2p_hw_shutdown(struct lpc31xx_dma_chan *edmac)
+{
+	uint32_t control;
+	printk("jds - m2p_channel_state\n");
+#if 0
+	control = readl(edmac->regs + M2P_CONTROL);
+	control &= ~(M2P_CONTROL_STALLINT | M2P_CONTROL_NFBINT);
+	m2p_set_control(edmac, control);
+
+	while (m2p_channel_state(edmac) >= M2P_STATE_ON)
+		cpu_relax();
+
+	m2p_set_control(edmac, 0);
+
+	while (m2p_channel_state(edmac) == M2P_STATE_STALL)
+		cpu_relax();
+#endif
+}
+
+static void m2p_fill_desc(struct lpc31xx_dma_chan *edmac)
+{
+	struct lpc31xx_dma_desc *desc;
+	uint32_t bus_addr;
+
+	printk("jds - m2p_fill_desc\n");
+	desc = lpc31xx_dma_get_active(edmac);
+	if (!desc) {
+		dev_warn(chan2dev(edmac), "M2P: empty descriptor list\n");
+		return;
+	}
+#if 0
+	if (lpc31xx_dma_chan_direction(&edmac->chan) == DMA_MEM_TO_DEV)
+		bus_addr = desc->src_addr;
+	else
+		bus_addr = desc->dst_addr;
+
+	if (edmac->buffer == 0) {
+		writel(desc->size, edmac->regs + M2P_MAXCNT0);
+		writel(bus_addr, edmac->regs + M2P_BASE0);
+	} else {
+		writel(desc->size, edmac->regs + M2P_MAXCNT1);
+		writel(bus_addr, edmac->regs + M2P_BASE1);
+	}
+#endif
+	edmac->buffer ^= 1;
+}
+
+static void m2p_hw_submit(struct lpc31xx_dma_chan *edmac)
+{
+	printk("jds - m2p_hw_submit\n");
+#if 0
+	uint32_t control = readl(edmac->regs + M2P_CONTROL);
+
+	m2p_fill_desc(edmac);
+	control |= M2P_CONTROL_STALLINT;
+
+	if (lpc31xx_dma_advance_active(edmac)) {
+		m2p_fill_desc(edmac);
+		control |= M2P_CONTROL_NFBINT;
+	}
+
+	m2p_set_control(edmac, control);
+#endif
+}
+
+static int m2p_hw_interrupt(struct lpc31xx_dma_chan *edmac)
+{
+	printk("jds - m2p_hw_interrupt\n");
+#if 0
+	uint32_t irq_status = readl(edmac->regs + M2P_INTERRUPT);
+	uint32_t control;
+
+	if (irq_status & M2P_INTERRUPT_ERROR) {
+		struct lpc31xx_dma_desc *desc = lpc31xx_dma_get_active(edmac);
+
+		/* Clear the error interrupt */
+		writel(1, edmac->regs + M2P_INTERRUPT);
+
+		/*
+		 * It seems that there is no easy way of reporting errors back
+		 * to client so we just report the error here and continue as
+		 * usual.
+		 *
+		 * Revisit this when there is a mechanism to report back the
+		 * errors.
+		 */
+		dev_err(chan2dev(edmac),
+			"DMA transfer failed! Details:\n"
+			"\tcookie	: %d\n"
+			"\tsrc_addr	: 0x%08x\n"
+			"\tdst_addr	: 0x%08x\n"
+			"\tsize		: %zu\n",
+			desc->txd.cookie, desc->src_addr, desc->dst_addr,
+			desc->size);
+	}
+
+	switch (irq_status & (M2P_INTERRUPT_STALL | M2P_INTERRUPT_NFB)) {
+	case M2P_INTERRUPT_STALL:
+		/* Disable interrupts */
+		control = readl(edmac->regs + M2P_CONTROL);
+		control &= ~(M2P_CONTROL_STALLINT | M2P_CONTROL_NFBINT);
+		m2p_set_control(edmac, control);
+
+		return INTERRUPT_DONE;
+
+	case M2P_INTERRUPT_NFB:
+		if (lpc31xx_dma_advance_active(edmac))
+			m2p_fill_desc(edmac);
+
+		return INTERRUPT_NEXT_BUFFER;
+	}
+#endif
+	return INTERRUPT_UNKNOWN;
+}
+
+/*
+ * DMA engine API implementation
+ */
+
+static struct lpc31xx_dma_desc *
+lpc31xx_dma_desc_get(struct lpc31xx_dma_chan *edmac)
+{
+	struct lpc31xx_dma_desc *desc, *_desc;
+	struct lpc31xx_dma_desc *ret = NULL;
+	unsigned long flags;
+
+	printk("jds - lpc31xx_dma_desc_get\n");
+	spin_lock_irqsave(&driver_lock, flags);
+	list_for_each_entry_safe(desc, _desc, &edmac->free_list, node) {
+		if (async_tx_test_ack(&desc->txd)) {
+			list_del_init(&desc->node);
+
+			/* Re-initialize the descriptor */
+			desc->src_addr = 0;
+			desc->dst_addr = 0;
+			desc->size = 0;
+			desc->complete = false;
+			desc->txd.cookie = 0;
+			desc->txd.callback = NULL;
+			desc->txd.callback_param = NULL;
+
+			ret = desc;
+			break;
+		}
+	}
+	spin_unlock_irqrestore(&driver_lock, flags);
+	return ret;
+}
+
+static void lpc31xx_dma_desc_put(struct lpc31xx_dma_chan *edmac,
+				struct lpc31xx_dma_desc *desc)
+{
+	if (desc) {
+		unsigned long flags;
+
+		spin_lock_irqsave(&driver_lock, flags);
+		list_splice_init(&desc->tx_list, &edmac->free_list);
+		list_add(&desc->node, &edmac->free_list);
+		spin_unlock_irqrestore(&driver_lock, flags);
+	}
+}
+
+/**
+ * lpc31xx_dma_advance_work - start processing the next pending transaction
+ * @edmac: channel
+ *
+ * If we have pending transactions queued and we are currently idling, this
+ * function takes the next queued transaction from the @edmac->queue and
+ * pushes it to the hardware for execution.
+ */
+static void lpc31xx_dma_advance_work(struct lpc31xx_dma_chan *edmac)
+{
+	struct lpc31xx_dma_desc *new;
+	unsigned long flags;
+
+	printk("jds - lpc31xx_dma_advance_work\n");
+	spin_lock_irqsave(&driver_lock, flags);
+	if (!list_empty(&edmac->active) || list_empty(&edmac->queue)) {
+		spin_unlock_irqrestore(&driver_lock, flags);
+		return;
+	}
+
+	/* Take the next descriptor from the pending queue */
+	new = list_first_entry(&edmac->queue, struct lpc31xx_dma_desc, node);
+	list_del_init(&new->node);
+
+	lpc31xx_dma_set_active(edmac, new);
+
+	/* Push it to the hardware */
+	m2p_hw_submit(edmac);
+	spin_unlock_irqrestore(&driver_lock, flags);
+}
+
+static void lpc31xx_dma_unmap_buffers(struct lpc31xx_dma_desc *desc)
+{
+	struct device *dev = desc->txd.chan->device->dev;
+
+	printk("jds - lpc31xx_dma_unmap_buffers\n");
+	if (!(desc->txd.flags & DMA_COMPL_SKIP_SRC_UNMAP)) {
+		if (desc->txd.flags & DMA_COMPL_SRC_UNMAP_SINGLE)
+			dma_unmap_single(dev, desc->src_addr, desc->size,
+					 DMA_TO_DEVICE);
+		else
+			dma_unmap_page(dev, desc->src_addr, desc->size,
+				       DMA_TO_DEVICE);
+	}
+	if (!(desc->txd.flags & DMA_COMPL_SKIP_DEST_UNMAP)) {
+		if (desc->txd.flags & DMA_COMPL_DEST_UNMAP_SINGLE)
+			dma_unmap_single(dev, desc->dst_addr, desc->size,
+					 DMA_FROM_DEVICE);
+		else
+			dma_unmap_page(dev, desc->dst_addr, desc->size,
+				       DMA_FROM_DEVICE);
+	}
+}
+
+static void lpc31xx_dma_tasklet(unsigned long data)
+{
+	struct lpc31xx_dma_chan *edmac = (struct lpc31xx_dma_chan *)data;
+	struct lpc31xx_dma_desc *desc, *d;
+	dma_async_tx_callback callback = NULL;
+	void *callback_param = NULL;
+	LIST_HEAD(list);
+
+	printk("jds - lpc31xx_dma_tasklet\n");
+	spin_lock_irq(&driver_lock);
+	/*
+	 * If dma_terminate_all() was called before we get to run, the active
+	 * list has become empty. If that happens we aren't supposed to do
+	 * anything more than call lpc31xx_dma_advance_work().
+	 */
+	desc = lpc31xx_dma_get_active(edmac);
+	if (desc) {
+		if (desc->complete) {
+			edmac->last_completed = desc->txd.cookie;
+			list_splice_init(&edmac->active, &list);
+		}
+		callback = desc->txd.callback;
+		callback_param = desc->txd.callback_param;
+	}
+	spin_unlock_irq(&driver_lock);
+
+	/* Pick up the next descriptor from the queue */
+	lpc31xx_dma_advance_work(edmac);
+
+	/* Now we can release all the chained descriptors */
+	list_for_each_entry_safe(desc, d, &list, node) {
+		/*
+		 * For the memcpy channels the API requires us to unmap the
+		 * buffers unless requested otherwise.
+		 */
+		if (!edmac->chan.private)
+			lpc31xx_dma_unmap_buffers(desc);
+
+		lpc31xx_dma_desc_put(edmac, desc);
+	}
+
+	if (callback)
+		callback(callback_param);
+}
+
+static irqreturn_t lpc31xx_dma_irq_handler(int irq, void *dev_id)
+{
+	struct lpc31xx_dma_chan *edmac = dev_id;
+	struct lpc31xx_dma_desc *desc;
+	irqreturn_t ret = IRQ_HANDLED;
+
+	printk("jds - lpc31xx_dma_irq_handler\n");
+	spin_lock(&driver_lock);
+
+	desc = lpc31xx_dma_get_active(edmac);
+	if (!desc) {
+		dev_warn(chan2dev(edmac),
+			 "got interrupt while active list is empty\n");
+		spin_unlock(&driver_lock);
+		return IRQ_NONE;
+	}
+
+	switch (m2p_hw_interrupt(edmac)) {
+	case INTERRUPT_DONE:
+		desc->complete = true;
+		tasklet_schedule(&edmac->tasklet);
+		break;
+
+	case INTERRUPT_NEXT_BUFFER:
+		if (test_bit(LPC31xx_DMA_IS_CYCLIC, &edmac->flags))
+			tasklet_schedule(&edmac->tasklet);
+		break;
+
+	default:
+		dev_warn(chan2dev(edmac), "unknown interrupt!\n");
+		ret = IRQ_NONE;
+		break;
+	}
+
+	spin_unlock(&driver_lock);
+	return ret;
+}
+
+/**
+ * lpc31xx_dma_tx_submit - set the prepared descriptor(s) to be executed
+ * @tx: descriptor to be executed
+ *
+ * Function will execute given descriptor on the hardware or if the hardware
+ * is busy, queue the descriptor to be executed later on. Returns cookie which
+ * can be used to poll the status of the descriptor.
+ */
+static dma_cookie_t lpc31xx_dma_tx_submit(struct dma_async_tx_descriptor *tx)
+{
+	struct lpc31xx_dma_chan *edmac = to_lpc31xx_dma_chan(tx->chan);
+	struct lpc31xx_dma_desc *desc;
+	dma_cookie_t cookie;
+	unsigned long flags;
+
+	printk("jds - lpc31xx_dma_tx_submit\n");
+	spin_lock_irqsave(&driver_lock, flags);
+
+	cookie = edmac->chan.cookie;
+
+	if (++cookie < 0)
+		cookie = 1;
+
+	desc = container_of(tx, struct lpc31xx_dma_desc, txd);
+
+	edmac->chan.cookie = cookie;
+	desc->txd.cookie = cookie;
+
+	/*
+	 * If nothing is currently processed, we push this descriptor
+	 * directly to the hardware. Otherwise we put the descriptor
+	 * to the pending queue.
+	 */
+	if (list_empty(&edmac->active)) {
+		lpc31xx_dma_set_active(edmac, desc);
+		m2p_hw_submit(edmac);
+	} else {
+		list_add_tail(&desc->node, &edmac->queue);
+	}
+
+	spin_unlock_irqrestore(&driver_lock, flags);
+	return cookie;
+}
+
+/**
+ * lpc31xx_dma_alloc_chan_resources - allocate resources for the channel
+ * @chan: channel to allocate resources
+ *
+ * Function allocates necessary resources for the given DMA channel and
+ * returns number of allocated descriptors for the channel. Negative errno
+ * is returned in case of failure.
+ */
+static int lpc31xx_dma_alloc_chan_resources(struct dma_chan *chan)
+{
+	struct lpc31xx_dma_chan *edmac = to_lpc31xx_dma_chan(chan);
+	struct lpc31xx_dma_data *data = chan->private;
+	const char *name = dma_chan_name(chan);
+	int ret, i;
+
+	printk("jds - lpc31xx_dma_alloc_chan_resources\n");
+	/* Sanity check the channel parameters */
+	if (data) {
+		if (data->port) {
+			if (data->direction != DMA_MEM_TO_DEV &&
+				data->direction != DMA_DEV_TO_MEM)
+				return -EINVAL;
+		}
+	}
+	if (data && data->name)
+		name = data->name;
+
+	lpc31xx_dma_increment_usage();
+
+	spin_lock_irq(&driver_lock);
+	edmac->last_completed = 1;
+	edmac->chan.cookie = 1;
+	ret = m2p_hw_setup(edmac);
+	spin_unlock_irq(&driver_lock);
+
+	if (ret)
+		goto fail;
+
+	for (i = 0; i < DMA_MAX_CHAN_DESCRIPTORS; i++) {
+		struct lpc31xx_dma_desc *desc;
+
+		desc = kzalloc(sizeof(*desc), GFP_KERNEL);
+		if (!desc) {
+			dev_warn(chan2dev(edmac), "not enough descriptors\n");
+			break;
+		}
+
+		INIT_LIST_HEAD(&desc->tx_list);
+
+		dma_async_tx_descriptor_init(&desc->txd, chan);
+		desc->txd.flags = DMA_CTRL_ACK;
+		desc->txd.tx_submit = lpc31xx_dma_tx_submit;
+
+		lpc31xx_dma_desc_put(edmac, desc);
+	}
+
+	return i;
+
+fail:
+	lpc31xx_dma_decrement_usage();
+
+	return ret;
+}
+
+/**
+ * lpc31xx_dma_free_chan_resources - release resources for the channel
+ * @chan: channel
+ *
+ * Function releases all the resources allocated for the given channel.
+ * The channel must be idle when this is called.
+ */
+static void lpc31xx_dma_free_chan_resources(struct dma_chan *chan)
+{
+	struct lpc31xx_dma_chan *edmac = to_lpc31xx_dma_chan(chan);
+	struct lpc31xx_dma_desc *desc, *d;
+	unsigned long flags;
+	LIST_HEAD(list);
+
+	printk("jds - lpc31xx_dma_free_chan_resources\n");
+	BUG_ON(!list_empty(&edmac->active));
+	BUG_ON(!list_empty(&edmac->queue));
+
+	spin_lock_irqsave(&driver_lock, flags);
+	m2p_hw_shutdown(edmac);
+	edmac->runtime_addr = 0;
+	edmac->runtime_ctrl = 0;
+	edmac->buffer = 0;
+	list_splice_init(&edmac->free_list, &list);
+	spin_unlock_irqrestore(&driver_lock, flags);
+
+	list_for_each_entry_safe(desc, d, &list, node)
+		kfree(desc);
+
+	lpc31xx_dma_decrement_usage();
+}
+
+/**
+ * lpc31xx_dma_prep_dma_memcpy - prepare a memcpy DMA operation
+ * @chan: channel
+ * @dest: destination bus address
+ * @src: source bus address
+ * @len: size of the transaction
+ * @flags: flags for the descriptor
+ *
+ * Returns a valid DMA descriptor or %NULL in case of failure.
+ */
+static struct dma_async_tx_descriptor *
+lpc31xx_dma_prep_dma_memcpy(struct dma_chan *chan, dma_addr_t dest,
+			   dma_addr_t src, size_t len, unsigned long flags)
+{
+	struct lpc31xx_dma_chan *edmac = to_lpc31xx_dma_chan(chan);
+	struct lpc31xx_dma_desc *desc, *first;
+	size_t bytes, offset;
+
+	printk("jds - lpc31xx_dma_prep_dma_memcpy\n");
+	first = NULL;
+	for (offset = 0; offset < len; offset += bytes) {
+		desc = lpc31xx_dma_desc_get(edmac);
+		if (!desc) {
+			dev_warn(chan2dev(edmac), "couln't get descriptor\n");
+			goto fail;
+		}
+
+		bytes = min_t(size_t, len - offset, DMA_MAX_TRANSFERS + 1);
+
+		desc->src_addr = src + offset;
+		desc->dst_addr = dest + offset;
+		desc->size = bytes;
+
+		if (!first)
+			first = desc;
+		else
+			list_add_tail(&desc->node, &first->tx_list);
+	}
+
+	first->txd.cookie = -EBUSY;
+	first->txd.flags = flags;
+
+	return &first->txd;
+fail:
+	lpc31xx_dma_desc_put(edmac, first);
+	return NULL;
+}
+
+/**
+ * lpc31xx_dma_prep_slave_sg - prepare a slave DMA operation
+ * @chan: channel
+ * @sgl: list of buffers to transfer
+ * @sg_len: number of entries in @sgl
+ * @dir: direction of tha DMA transfer
+ * @flags: flags for the descriptor
+ *
+ * Returns a valid DMA descriptor or %NULL in case of failure.
+ */
+static struct dma_async_tx_descriptor *
+lpc31xx_dma_prep_slave_sg(struct dma_chan *chan, struct scatterlist *sgl,
+			 unsigned int sg_len, enum dma_transfer_direction dir,
+			 unsigned long flags)
+{
+	struct lpc31xx_dma_chan *edmac = to_lpc31xx_dma_chan(chan);
+	struct lpc31xx_dma_desc *desc, *first;
+	struct scatterlist *sg;
+	int i;
+
+	printk("jds - lpc31xx_dma_prep_slave_sg\n");
+#if 0
+	if (!edmac->edma->m2m && dir != lpc31xx_dma_chan_direction(chan)) {
+		dev_warn(chan2dev(edmac),
+			 "channel was configured with different direction\n");
+		return NULL;
+	}
+#endif
+	if (test_bit(LPC31xx_DMA_IS_CYCLIC, &edmac->flags)) {
+		dev_warn(chan2dev(edmac),
+			 "channel is already used for cyclic transfers\n");
+		return NULL;
+	}
+
+	first = NULL;
+	for_each_sg(sgl, sg, sg_len, i) {
+		size_t sg_len = sg_dma_len(sg);
+
+		if (sg_len > DMA_MAX_TRANSFERS) {
+			dev_warn(chan2dev(edmac), "too big transfer size %d\n",
+				 sg_len);
+			goto fail;
+		}
+
+		desc = lpc31xx_dma_desc_get(edmac);
+		if (!desc) {
+			dev_warn(chan2dev(edmac), "couln't get descriptor\n");
+			goto fail;
+		}
+
+		if (dir == DMA_MEM_TO_DEV) {
+			desc->src_addr = sg_dma_address(sg);
+			desc->dst_addr = edmac->runtime_addr;
+		} else {
+			desc->src_addr = edmac->runtime_addr;
+			desc->dst_addr = sg_dma_address(sg);
+		}
+		desc->size = sg_len;
+
+		if (!first)
+			first = desc;
+		else
+			list_add_tail(&desc->node, &first->tx_list);
+	}
+
+	first->txd.cookie = -EBUSY;
+	first->txd.flags = flags;
+
+	return &first->txd;
+
+fail:
+	lpc31xx_dma_desc_put(edmac, first);
+	return NULL;
+}
+
+/**
+ * lpc31xx_dma_prep_dma_cyclic - prepare a cyclic DMA operation
+ * @chan: channel
+ * @dma_addr: DMA mapped address of the buffer
+ * @buf_len: length of the buffer (in bytes)
+ * @period_len: lenght of a single period
+ * @dir: direction of the operation
+ *
+ * Prepares a descriptor for cyclic DMA operation. This means that once the
+ * descriptor is submitted, we will be submitting in a @period_len sized
+ * buffers and calling callback once the period has been elapsed. Transfer
+ * terminates only when client calls dmaengine_terminate_all() for this
+ * channel.
+ *
+ * Returns a valid DMA descriptor or %NULL in case of failure.
+ */
+static struct dma_async_tx_descriptor *
+lpc31xx_dma_prep_dma_cyclic(struct dma_chan *chan, dma_addr_t dma_addr,
+			   size_t buf_len, size_t period_len,
+			   enum dma_transfer_direction dir)
+{
+	struct lpc31xx_dma_chan *edmac = to_lpc31xx_dma_chan(chan);
+	struct lpc31xx_dma_desc *desc, *first;
+	size_t offset = 0;
+
+	printk("jds - lpc31xx_dma_prep_dma_cyclic\n");
+#if 0
+	if (!edmac->edma->m2m && dir != lpc31xx_dma_chan_direction(chan)) {
+		dev_warn(chan2dev(edmac),
+			 "channel was configured with different direction\n");
+		return NULL;
+	}
+#endif
+	if (test_and_set_bit(LPC31xx_DMA_IS_CYCLIC, &edmac->flags)) {
+		dev_warn(chan2dev(edmac),
+			 "channel is already used for cyclic transfers\n");
+		return NULL;
+	}
+
+	if (period_len > DMA_MAX_TRANSFERS + 1) {
+		dev_warn(chan2dev(edmac), "too big period length %d\n",
+			 period_len);
+		return NULL;
+	}
+
+	/* Split the buffer into period size chunks */
+	first = NULL;
+	for (offset = 0; offset < buf_len; offset += period_len) {
+		desc = lpc31xx_dma_desc_get(edmac);
+		if (!desc) {
+			dev_warn(chan2dev(edmac), "couln't get descriptor\n");
+			goto fail;
+		}
+
+		if (dir == DMA_MEM_TO_DEV) {
+			desc->src_addr = dma_addr + offset;
+			desc->dst_addr = edmac->runtime_addr;
+		} else {
+			desc->src_addr = edmac->runtime_addr;
+			desc->dst_addr = dma_addr + offset;
+		}
+
+		desc->size = period_len;
+
+		if (!first)
+			first = desc;
+		else
+			list_add_tail(&desc->node, &first->tx_list);
+	}
+
+	first->txd.cookie = -EBUSY;
+
+	return &first->txd;
+
+fail:
+	lpc31xx_dma_desc_put(edmac, first);
+	return NULL;
+}
+
+/**
+ * lpc31xx_dma_terminate_all - terminate all transactions
+ * @edmac: channel
+ *
+ * Stops all DMA transactions. All descriptors are put back to the
+ * @edmac->free_list and callbacks are _not_ called.
+ */
+static int lpc31xx_dma_terminate_all(struct lpc31xx_dma_chan *edmac)
+{
+	struct lpc31xx_dma_desc *desc, *_d;
+	unsigned long flags;
+	LIST_HEAD(list);
+
+	printk("jds - lpc31xx_dma_terminate_all\n");
+	spin_lock_irqsave(&driver_lock, flags);
+	/* First we disable and flush the DMA channel */
+	m2p_hw_shutdown(edmac);
+	clear_bit(LPC31xx_DMA_IS_CYCLIC, &edmac->flags);
+	list_splice_init(&edmac->active, &list);
+	list_splice_init(&edmac->queue, &list);
+	/*
+	 * We then re-enable the channel. This way we can continue submitting
+	 * the descriptors by just calling m2p_hw_submit() again.
+	 */
+	m2p_hw_setup(edmac);
+	spin_unlock_irqrestore(&driver_lock, flags);
+
+	list_for_each_entry_safe(desc, _d, &list, node)
+		lpc31xx_dma_desc_put(edmac, desc);
+
+	return 0;
+}
+
+static int lpc31xx_dma_slave_config(struct lpc31xx_dma_chan *edmac,
+				   struct dma_slave_config *config)
+{
+	enum dma_slave_buswidth width;
+	unsigned long flags;
+	uint32_t addr, ctrl;
+
+	printk("jds - lpc31xx_dma_slave_config\n");
+	switch (config->direction) {
+	case DMA_DEV_TO_MEM:
+		width = config->src_addr_width;
+		addr = config->src_addr;
+		break;
+
+	case DMA_MEM_TO_DEV:
+		width = config->dst_addr_width;
+		addr = config->dst_addr;
+		break;
+
+	default:
+		return -EINVAL;
+	}
+
+	switch (width) {
+#if 0
+	case DMA_SLAVE_BUSWIDTH_1_BYTE:
+		ctrl = 0;
+		break;
+	case DMA_SLAVE_BUSWIDTH_2_BYTES:
+		ctrl = M2M_CONTROL_PW_16;
+		break;
+	case DMA_SLAVE_BUSWIDTH_4_BYTES:
+		ctrl = M2M_CONTROL_PW_32;
+		break;
+#endif
+	default:
+		return -EINVAL;
+	}
+
+	spin_lock_irqsave(&driver_lock, flags);
+	edmac->runtime_addr = addr;
+	edmac->runtime_ctrl = ctrl;
+	spin_unlock_irqrestore(&driver_lock, flags);
+
+	return 0;
+}
+
+/**
+ * lpc31xx_dma_control - manipulate all pending operations on a channel
+ * @chan: channel
+ * @cmd: control command to perform
+ * @arg: optional argument
+ *
+ * Controls the channel. Function returns %0 in case of success or negative
+ * error in case of failure.
+ */
+static int lpc31xx_dma_control(struct dma_chan *chan, enum dma_ctrl_cmd cmd,
+			      unsigned long arg)
+{
+	struct lpc31xx_dma_chan *edmac = to_lpc31xx_dma_chan(chan);
+	struct dma_slave_config *config;
+
+	printk("jds - lpc31xx_dma_control\n");
+	switch (cmd) {
+	case DMA_TERMINATE_ALL:
+		return lpc31xx_dma_terminate_all(edmac);
+
+	case DMA_SLAVE_CONFIG:
+		config = (struct dma_slave_config *)arg;
+		return lpc31xx_dma_slave_config(edmac, config);
+
+	default:
+		break;
+	}
+
+	return -ENOSYS;
+}
+
+/**
+ * lpc31xx_dma_tx_status - check if a transaction is completed
+ * @chan: channel
+ * @cookie: transaction specific cookie
+ * @state: state of the transaction is stored here if given
+ *
+ * This function can be used to query state of a given transaction.
+ */
+static enum dma_status lpc31xx_dma_tx_status(struct dma_chan *chan,
+					    dma_cookie_t cookie,
+					    struct dma_tx_state *state)
+{
+	struct lpc31xx_dma_chan *edmac = to_lpc31xx_dma_chan(chan);
+	dma_cookie_t last_used, last_completed;
+	enum dma_status ret;
+	unsigned long flags;
+
+	printk("jds - lpc31xx_dma_tx_status\n");
+	spin_lock_irqsave(&driver_lock, flags);
+	last_used = chan->cookie;
+	last_completed = edmac->last_completed;
+	spin_unlock_irqrestore(&driver_lock, flags);
+
+	ret = dma_async_is_complete(cookie, last_completed, last_used);
+	dma_set_tx_state(state, last_completed, last_used, 0);
+
+	return ret;
+}
+
+/**
+ * lpc31xx_dma_issue_pending - push pending transactions to the hardware
+ * @chan: channel
+ *
+ * When this function is called, all pending transactions are pushed to the
+ * hardware and executed.
+ */
+static void lpc31xx_dma_issue_pending(struct dma_chan *chan)
+{
+	printk("jds - lpc31xx_dma_issue_pending\n");
+	lpc31xx_dma_advance_work(to_lpc31xx_dma_chan(chan));
+}
+
+static int __init lpc31xx_dma_probe(struct platform_device *pdev)
+{
+	struct lpc31xx_dma_engine *edma;
+	int ret, i;
+
+	printk("JDS - lpc31xx_dma_probe 1\n");
+	spin_lock_init(&driver_lock);
+
+	edma = kzalloc(sizeof(*edma), GFP_KERNEL);
+	if (!edma)
+		return -ENOMEM;
+
+	INIT_LIST_HEAD(&edma->dma_dev.channels);
+
+	/* Initialize channel parameters */
+	for (i = 0; i < DMA_MAX_CHANNELS; i++) {
+		struct lpc31xx_dma_chan *edmac = &edma->channels[i];
+
+		edmac->chan.device = &edma->dma_dev;
+		edmac->edma = edma;
+		edmac->number = i;
+
+		INIT_LIST_HEAD(&edmac->active);
+		INIT_LIST_HEAD(&edmac->queue);
+		INIT_LIST_HEAD(&edmac->free_list);
+
+		tasklet_init(&edmac->tasklet, lpc31xx_dma_tasklet,
+			     (unsigned long)edmac);
+
+		/* Add the channel to the DMAC list */
+		list_add_tail(&edmac->chan.device_node, &edma->dma_dev.channels);
+	}
+
+	dma_cap_zero(edma->dma_dev.cap_mask);
+	dma_cap_set(DMA_MEMCPY, edma->dma_dev.cap_mask);
+	dma_cap_set(DMA_SLAVE, edma->dma_dev.cap_mask);
+	dma_cap_set(DMA_CYCLIC, edma->dma_dev.cap_mask);
+
+	edma->dma_dev.dev = &pdev->dev;
+	edma->dma_dev.device_alloc_chan_resources = lpc31xx_dma_alloc_chan_resources;
+	edma->dma_dev.device_free_chan_resources = lpc31xx_dma_free_chan_resources;
+	edma->dma_dev.device_tx_status = lpc31xx_dma_tx_status;
+	edma->dma_dev.device_prep_slave_sg = lpc31xx_dma_prep_slave_sg;
+	edma->dma_dev.device_prep_dma_cyclic = lpc31xx_dma_prep_dma_cyclic;
+	edma->dma_dev.device_prep_dma_memcpy = lpc31xx_dma_prep_dma_memcpy;
+	edma->dma_dev.device_control = lpc31xx_dma_control;
+	edma->dma_dev.device_issue_pending = lpc31xx_dma_issue_pending;
+
+	platform_set_drvdata(pdev, edma);
+
+	ret = dma_async_device_register(&edma->dma_dev);
+	if (ret) {
+		dev_err(&pdev->dev, "unable to register\n");
+		goto err_init;
+	}
+
+	dma_irq_mask = 0xFFFFFFFF;
+	DMACH_IRQ_MASK = dma_irq_mask;
+	ret = request_irq (IRQ_DMA, lpc31xx_dma_irq_handler, 0, "DMAC", edma);
+	if (ret)
+		printk (KERN_ERR "request_irq() returned error %d\n", ret);
+
+	printk("JDS - lpc31xx_dma_probe 2\n");
+	return 0;
+
+err_init:
+	kfree(edma);
+	printk("JDS - lpc31xx_dma_probe err %d\n", ret);
+	return ret;
+}
+
+static int __exit lpc31xx_dma_remove(struct platform_device *pdev)
+{
+	struct lpc31xx_dma_engine *edma = platform_get_drvdata(pdev);
+
+	dma_async_device_unregister(&edma->dma_dev);
+	kfree(edma);
+	return 0;
+}
+
+#if defined(CONFIG_OF)
+static const struct of_device_id lpc313x_dma_of_match[] = {
+	{ .compatible = "nxp,lpc31xx-dma" },
+	{},
+};
+MODULE_DEVICE_TABLE(of, lpc313x_dma_of_match);
+#endif
+
+static struct platform_driver lpc31xx_dma_driver = {
+	.driver = {
+			.name	= "lpc31xx-dma",
+			.owner = THIS_MODULE,
+#ifdef CONFIG_OF
+			.of_match_table = lpc313x_dma_of_match,
+#endif
+	},
+	.remove		= __exit_p(lpc31xx_dma_remove),
+};
+
+static int __init lpc31xx_dma_module_init(void)
+{
+	printk("JDS - lpc31xx_dma_module_init\n");
+	return platform_driver_probe(&lpc31xx_dma_driver, lpc31xx_dma_probe);
+}
+subsys_initcall(lpc31xx_dma_module_init);
+
+MODULE_AUTHOR("Jon Smirl <jonsmirl@gmail.com>");
+MODULE_DESCRIPTION("lpc31xx dma driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/gpio/gpio-lpc31xx.c b/drivers/gpio/gpio-lpc31xx.c
index 6e523fa..19f5e42 100644
--- a/drivers/gpio/gpio-lpc31xx.c
+++ b/drivers/gpio/gpio-lpc31xx.c
@@ -23,6 +23,14 @@
 #include <asm/irq.h>
 #include <mach/gpio.h>
 
+#define GPIO_STATE	0x00
+#define GPIO_STATE_M0	0x10
+#define GPIO_M0_SET	0x14
+#define GPIO_M0_RESET	0x18
+#define GPIO_STATE_M1	0x20
+#define GPIO_M1_SET	0x24
+#define GPIO_M1_RESET	0x28
+
 
 /**
  * struct lpc313x_gpio_chip - wrapper for specific implementation of gpio
@@ -40,175 +48,73 @@ struct lpc313x_gpio_chip {
 	struct lpc313x_gpio_pm	*pm;
 	int			base;
 #ifdef CONFIG_PM
-	u32			pm_save[4];
+	uint32_t		pm_save[4];
 #endif
 };
 
-static inline struct lpc313x_gpio_chip *to_lpc313x_gpio(struct gpio_chip *gpc)
+static int inline *gpc(void __iomem *base, int reg)
 {
-	return container_of(gpc, struct lpc313x_gpio_chip, chip);
+	return (int *)(base + reg);
 }
 
-struct lpc313x_gpio_chip lpc313x_gpios[] = {
-	[0] = {
-		.base	= GPIO_PHYS,
-		.chip	= {
-			.base			= IOCONF_EBI_MCI,
-			.owner			= THIS_MODULE,
-			.label			= "EBI_MCI",
-			.ngpio			= 32,
-		},
-	},
-	[1] = {
-		.base	= GPIO_PHYS,
-		.chip	= {
-			.base			= IOCONF_EBI_I2STX_0,
-			.owner			= THIS_MODULE,
-			.label			= "EBI_I2STX_0",
-			.ngpio			= 10,
-		},
-	},
-	[2] = {
-		.base	= GPIO_PHYS,
-		.chip	= {
-			.base			= IOCONF_CGU,
-			.owner			= THIS_MODULE,
-			.label			= "CGU",
-			.ngpio			= 1,
-		},
-	},
-	[3] = {
-		.base	= GPIO_PHYS,
-		.chip	= {
-			.base			= IOCONF_I2SRX_0,
-			.owner			= THIS_MODULE,
-			.label			= "I2SRX_0",
-			.ngpio			= 3,
-		},
-	},
-	[4] = {
-		.base	= GPIO_PHYS,
-		.chip	= {
-			.base			= IOCONF_I2SRX_1,
-			.owner			= THIS_MODULE,
-			.label			= "I2SRX_0",
-			.ngpio			= 3,
-		},
-	},
-	[5] = {
-		.base	= GPIO_PHYS,
-		.chip	= {
-			.base			= IOCONF_I2STX_1,
-			.owner			= THIS_MODULE,
-			.label			= "I2STX_1",
-			.ngpio			= 4,
-		},
-	},
-	[6] = {
-		.base	= GPIO_PHYS,
-		.chip	= {
-			.base			= IOCONF_EBI,
-			.owner			= THIS_MODULE,
-			.label			= "EBI",
-			.ngpio			= 16,
-		},
-	},
-	[7] = {
-		.base	= GPIO_PHYS,
-		.chip	= {
-			.base			= IOCONF_GPIO,
-			.owner			= THIS_MODULE,
-			.label			= "GPIO",
-			.ngpio			= 15,
-		},
-	},
-	[8] = {
-		.base	= GPIO_PHYS,
-		.chip	= {
-			.base			= IOCONF_I2C1,
-			.owner			= THIS_MODULE,
-			.label			= "I2C1",
-			.ngpio			= 2,
-		},
-	},
-	[9] = {
-		.base	= GPIO_PHYS,
-		.chip	= {
-			.base			= IOCONF_SPI,
-			.owner			= THIS_MODULE,
-			.label			= "SPI",
-			.ngpio			= 5,
-		},
-	},
-	[10] = {
-		.base	= GPIO_PHYS,
-		.chip	= {
-			.base			= IOCONF_NAND_CTRL,
-			.owner			= THIS_MODULE,
-			.label			= "NAND_CTRL",
-			.ngpio			= 4,
-		},
-	},
-	[11] = {
-		.base	= GPIO_PHYS,
-		.chip	= {
-			.base			= IOCONF_PWM,
-			.owner			= THIS_MODULE,
-			.label			= "PWM",
-			.ngpio			= 1,
-		},
-	},
-	[12] = {
-		.base	= GPIO_PHYS,
-		.chip	= {
-			.base			= IOCONF_UART,
-			.owner			= THIS_MODULE,
-			.label			= "UART",
-			.ngpio			= 2,
-		},
-	},
-};
-
-int lpc313x_gpio_direction_output(unsigned gpio, int value)
+static int lpc3131_gpio_direction_input(struct gpio_chip *chip, unsigned gpio)
 {
+	struct of_mm_gpio_chip *mm_gc = to_of_mm_gpio_chip(chip);
+	void __iomem *base = mm_gc->regs;
+	int pin = 1 << gpio;
 	unsigned long flags;
-	int port = (gpio & GPIO_PORT_MASK);
-	int pin = 1 << (gpio & GPIO_PIN_MASK);
 
 	raw_local_irq_save(flags);
-
-	GPIO_M1_SET(port) = pin;
-
-	if(value) {
-		GPIO_M0_SET(port) = pin;
-	} else {
-		GPIO_M0_RESET(port) = pin;
-	}
-
+	*gpc(base, GPIO_M1_RESET) = pin;
+	*gpc(base, GPIO_M0_RESET) = pin;
 	raw_local_irq_restore(flags);
 	return 0;
 }
 
-EXPORT_SYMBOL(lpc313x_gpio_direction_output);
-
-static inline int lpc3131_gpio_direction_input(struct gpio_chip *chip, unsigned offset)
+static int lpc3131_gpio_direction_output(struct gpio_chip *chip, unsigned gpio, int value)
 {
-	return lpc313x_gpio_direction_input(chip->base + offset);
+	struct of_mm_gpio_chip *mm_gc = to_of_mm_gpio_chip(chip);
+	int __iomem *base = mm_gc->regs;
+	int pin = 1 << gpio;
+	unsigned long flags;
+
+	raw_local_irq_save(flags);
+	*gpc(base, GPIO_M1_SET) = pin;
+	if (value)
+		*gpc(base, GPIO_M0_SET) = pin;
+	else
+		*gpc(base, GPIO_M0_RESET) = pin;
+	raw_local_irq_restore(flags);
+	return 0;
 }
 
-static inline int lpc3131_gpio_direction_output(struct gpio_chip *chip, unsigned offset, int value)
+static int lpc3131_gpio_get_value(struct gpio_chip *chip, unsigned gpio)
 {
-	return lpc313x_gpio_direction_output(chip->base + offset, value);
+	struct of_mm_gpio_chip *mm_gc = to_of_mm_gpio_chip(chip);
+	int __iomem *base = mm_gc->regs;
+	int pin = 1 << gpio;
+	int value;
+
+	value = ((*base & pin) != 0);
+	return value;
 }
 
-static inline int lpc3131_gpio_get_value(struct gpio_chip *chip, unsigned offset)
+static void lpc3131_gpio_set_value(struct gpio_chip *chip, unsigned gpio, int value)
 {
-	return lpc313x_gpio_get_value(chip->base + offset);
+	struct of_mm_gpio_chip *mm_gc = to_of_mm_gpio_chip(chip);
+	int __iomem *base = mm_gc->regs;
+	int pin = 1 << gpio;
+
+	if (value)
+		*gpc(base, GPIO_M0_SET) = pin;
+	else
+		*gpc(base, GPIO_M0_RESET) = pin;
 }
 
-static inline void lpc3131_gpio_set_value(struct gpio_chip *chip, unsigned offset, int value)
+static int lpc3131_gpio_to_irq(struct gpio_chip *chip, int irq)
 {
-	lpc313x_gpio_set_value(chip->base + offset, value);
+	printk("------------- implement lpc3131_gpio_to_irq -------------\n");
+	return -ENOENT;
 }
 
 static int lpc313x_gpiochip_remove(struct platform_device *ofdev)
@@ -233,6 +139,7 @@ static int __devinit lpc313x_simple_gpiochip_probe(struct platform_device *ofdev
 	gc->direction_output = lpc3131_gpio_direction_output;
 	gc->get              = lpc3131_gpio_get_value;
 	gc->set              = lpc3131_gpio_set_value;
+	gc->to_irq	     = lpc3131_gpio_to_irq;
 
 	ret = of_mm_gpiochip_add(ofdev->dev.of_node, chip);
 	if (ret)
diff --git a/drivers/mmc/host/lpc31xx_mmc.c b/drivers/mmc/host/lpc31xx_mmc.c
index a9a7dfa..e4190c0 100644
--- a/drivers/mmc/host/lpc31xx_mmc.c
+++ b/drivers/mmc/host/lpc31xx_mmc.c
@@ -590,7 +590,7 @@ void lpc313x_mci_setup_bus(struct lpc313x_mci_slot *slot)
 
 static void lpc313x_mci_select_slot(struct lpc313x_mci_slot *slot, int enable)
 {
-	if (slot->gpio_select >= 0) {
+	if (gpio_is_valid(slot->gpio_select)) {
 		printk("lpc313x_mci_select_slot %d\n", slot->gpio_select);
 		gpio_set_value(slot->gpio_select, enable);
 	}
@@ -603,7 +603,7 @@ static void lpc313x_mci_set_power(struct lpc313x_mci_slot *slot, int enable)
 	 * power management so use the always enable power
 	 * jumper.
 	 */
-	if (slot->gpio_power >= 0) {
+	if (gpio_is_valid(slot->gpio_power)) {
 		printk("lpc313x_mci_set_power %d\n", slot->gpio_power);
 		gpio_set_value(slot->gpio_power, enable);
 	}
@@ -740,7 +740,7 @@ static int lpc313x_mci_get_wp(struct mmc_host *mmc)
 	int			read_only = -ENOSYS;
 	struct lpc313x_mci_slot	*slot = mmc_priv(mmc);
 
-	if (slot->gpio_wp >= 0) {
+	if (gpio_is_valid(slot->gpio_wp)) {
 		read_only =  gpio_get_value(slot->gpio_wp);
 		dev_dbg(&mmc->class_dev, "card is %s\n",
 				read_only ? "read-only" : "read-write");
@@ -753,7 +753,7 @@ static int lpc313x_mci_get_cd(struct lpc313x_mci_slot *slot)
 {
 	int			present = -ENOSYS;
 
-	if (slot->gpio_cd >= 0) {
+	if (gpio_is_valid(slot->gpio_cd)) {
 		present = !gpio_get_value(slot->gpio_cd);
 		dev_vdbg(&slot->mmc->class_dev, "card is %spresent\n", present ? "" : "not ");
 	}
@@ -1357,6 +1357,7 @@ lpc313x_mci_init_slot(struct lpc313x_mci *host, struct device_node *np)
 	const u32 *voltage_ranges;
 	const int *width;
 	int i, ret, num_ranges, level;
+	enum of_gpio_flags flags;
 
 	mmc = mmc_alloc_host(sizeof(struct lpc313x_mci_slot), &host->pdev->dev);
 
@@ -1368,19 +1369,20 @@ lpc313x_mci_init_slot(struct lpc313x_mci *host, struct device_node *np)
 
 	slot->mmc = mmc;
 	slot->host = host;
-	slot->gpio_cd = of_get_named_gpio(np, "gpio-cd", 0);
-	if (slot->gpio_cd >= 0) {
+
+	slot->gpio_cd = of_get_named_gpio_flags(np, "gpios", 0, &flags);
+	if (gpio_is_valid(slot->gpio_cd)) {
 		gpio_request(slot->gpio_cd, "mmc cd");
 		gpio_direction_input(slot->gpio_cd);
 	}
-	slot->gpio_wp = of_get_named_gpio(np, "gpio-wp", 0);
-	if (slot->gpio_wp >= 0)
+	slot->gpio_wp = of_get_named_gpio_flags(np, "gpios", 1, &flags);
+	if (gpio_is_valid(slot->gpio_wp))
 		gpio_request(slot->gpio_cd, "mmc wp");
-	slot->gpio_power = of_get_named_gpio(np, "gpio-power", 0);
-	if (slot->gpio_power >= 0)
+	slot->gpio_power = of_get_named_gpio_flags(np, "gpios", 2, &flags);
+	if (gpio_is_valid(slot->gpio_power))
 		gpio_request(slot->gpio_cd, "mmc power");
-	slot->gpio_select = of_get_named_gpio(np, "gpio-select", 0);
-	if (slot->gpio_select >= 0)
+	slot->gpio_select = of_get_named_gpio_flags(np, "gpios", 3, &flags);
+	if (gpio_is_valid(slot->gpio_select))
 		gpio_request(slot->gpio_select, "mmc select");
 
 	mmc->ops = &lpc313x_mci_ops;
@@ -1558,7 +1560,10 @@ static int lpc313x_mci_probe(struct platform_device *pdev)
 	SYS_MUX_GPIO_MCI = 1;
 
 	/* set the pins as driven by IP in IOCONF */
+#if 0
+	/* fixme */
 	GPIO_DRV_IP(IOCONF_EBI_MCI, 0xF0000003);
+#endif
 
 	/* set delay gates */
 	SYS_SDMMC_DELAYMODES = 0x1B;
diff --git a/drivers/net/ethernet/davicom/dm9000.c b/drivers/net/ethernet/davicom/dm9000.c
index af228a2..41831c8 100644
--- a/drivers/net/ethernet/davicom/dm9000.c
+++ b/drivers/net/ethernet/davicom/dm9000.c
@@ -35,11 +35,15 @@
 #include <linux/platform_device.h>
 #include <linux/irq.h>
 #include <linux/slab.h>
+#include <linux/of_gpio.h>
 
 #include <asm/delay.h>
 #include <asm/irq.h>
 #include <asm/io.h>
 
+#include <linux/gpio.h>
+#include <mach/gpio.h>
+
 #include "dm9000.h"
 
 /* Board/System/Debug information/definition ---------------- */
@@ -59,7 +63,7 @@ MODULE_PARM_DESC(watchdog, "transmit timeout in milliseconds");
 /*
  * Debug messages level
  */
-static int debug;
+static int debug = 4;
 module_param(debug, int, 0644);
 MODULE_PARM_DESC(debug, "dm9000 debug level (0-4)");
 
@@ -658,6 +662,7 @@ dm9000_poll_work(struct work_struct *w)
 	board_info_t *db = container_of(dw, board_info_t, phy_poll);
 	struct net_device *ndev = db->ndev;
 
+printk("dm9000_poll_work\n");
 	if (db->flags & DM9000_PLATF_SIMPLE_PHY &&
 	    !(db->flags & DM9000_PLATF_EXT_PHY)) {
 		unsigned nsr = dm9000_read_locked(db, DM9000_NSR);
@@ -691,17 +696,18 @@ static void
 dm9000_release_board(struct platform_device *pdev, struct board_info *db)
 {
 	/* unmap our resources */
-
 	iounmap(db->io_addr);
 	iounmap(db->io_data);
 
 	/* release the resources */
-
-	release_resource(db->data_req);
-	kfree(db->data_req);
-
-	release_resource(db->addr_req);
-	kfree(db->addr_req);
+	if (db->data_req) {
+		release_resource(db->data_req);
+		kfree(db->data_req);
+	}
+	if (db->addr_req) {
+		release_resource(db->addr_req);
+		kfree(db->addr_req);
+	}
 }
 
 static unsigned char dm9000_type_to_char(enum dm9000_type type)
@@ -1065,6 +1071,7 @@ static irqreturn_t dm9000_interrupt(int irq, void *dev_id)
 	unsigned long flags;
 	u8 reg_save;
 
+	printk("dm9000_interrupt\n");
 	dm9000_dbg(db, 3, "entering %s\n", __func__);
 
 	/* A real interrupt coming */
@@ -1174,6 +1181,8 @@ dm9000_open(struct net_device *dev)
 	/* If there is no IRQ type specified, default to something that
 	 * may work, and tell the user that this is a problem */
 
+	irqflags |= IRQ_TYPE_LEVEL_HIGH;
+
 	if (irqflags == IRQF_TRIGGER_NONE)
 		dev_warn(db->dev, "WARNING: no IRQ resource flags set.\n");
 
@@ -1357,6 +1366,31 @@ static const struct net_device_ops dm9000_netdev_ops = {
 #endif
 };
 
+# define DM_IO_DELAY()	do { gpio_get_value(GPIO_MNAND_RYBN3);} while(0)
+
+static void dm9000_dumpblk(void __iomem *reg, int count)
+{
+	int i;
+	int tmp;
+
+	count = (count + 1) >> 1;
+	for (i = 0; i < count; i++) {
+		DM_IO_DELAY();
+		tmp = readw(reg);
+	}
+}
+
+static void dm9000_inblk(void __iomem *reg, void *data, int count)
+{
+	int i;
+	u16* pdata = (u16*)data;
+	count = (count + 1) >> 1;
+	for (i = 0; i < count; i++) {
+		DM_IO_DELAY();
+		*pdata++ = readw(reg);
+	}
+}
+
 /*
  * Search DM9000 board, allocate space and register it
  */
@@ -1461,6 +1495,8 @@ dm9000_probe(struct platform_device *pdev)
 		ret = -EINVAL;
 		goto out;
 	}
+/* fixme */
+pdata->flags		= DM9000_PLATF_16BITONLY | DM9000_PLATF_NO_EEPROM | DM9000_PLATF_SIMPLE_PHY;
 
 	/* fill in parameters for net-dev structure */
 	ndev->base_addr = (unsigned long)db->io_addr;
@@ -1487,13 +1523,15 @@ dm9000_probe(struct platform_device *pdev)
 		 * over-rides */
 
 		if (pdata->inblk != NULL)
-			db->inblk = pdata->inblk;
+//			db->inblk = pdata->inblk;
+			db->inblk = dm9000_inblk;
 
 		if (pdata->outblk != NULL)
 			db->outblk = pdata->outblk;
 
 		if (pdata->dumpblk != NULL)
-			db->dumpblk = pdata->dumpblk;
+//			db->dumpblk = pdata->dumpblk;
+			db->dumpblk = dm9000_dumpblk;
 
 		db->flags = pdata->flags;
 	}
diff --git a/drivers/spi/spi-lpc313x.c b/drivers/spi/spi-lpc313x.c
index 1c45d8f..5a982c7 100644
--- a/drivers/spi/spi-lpc313x.c
+++ b/drivers/spi/spi-lpc313x.c
@@ -1,108 +1,311 @@
 /*
- * drivers/spi/spi_lpc313x.c
+ * Driver for NXP LPC31xx SPI controller.
  *
- * Copyright (C) 2009 NXP Semiconductors
+ * Copyright (C) 2012 Jon Smirl <jonsmirl@gmail.com>
  *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- *
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
- *
- * LPC313X SPI notes
+ * Derived off from the lpc31xx SPI driver
  *
- * The LPC313X SPI Linux driver supports many chip selects using GPO based CS
- * (hardware chip selects are not supported due to timing constraints), clock
- * speeds up to 45MBps, data widths from 4 to 16 bits, DMA support, and full
- * power management.
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
  */
 
 #define DEBUG
+//#define jds_printk printk
+#define jds_printk(format, arg...) ({if (0) printk(format, ##arg);})
 
-#include <linux/module.h>
-#include <linux/init.h>
+#include <linux/io.h>
+#include <linux/clk.h>
+#include <linux/err.h>
 #include <linux/delay.h>
-#include <linux/errno.h>
+#include <linux/device.h>
+#include <linux/dmaengine.h>
+#include <linux/bitops.h>
 #include <linux/interrupt.h>
+#include <linux/module.h>
 #include <linux/platform_device.h>
-#include <linux/sched.h>
-#include <linux/spinlock.h>
 #include <linux/workqueue.h>
+#include <linux/sched.h>
+#include <linux/scatterlist.h>
 #include <linux/spi/spi.h>
-#include <linux/err.h>
-#include <linux/clk.h>
-#include <linux/io.h>
 #include <linux/dma-mapping.h>
+#include <linux/of_gpio.h>
 
-#include <mach/registers.h>
 #include <mach/dma.h>
-#include <mach/board.h>
-#include <mach/gpio.h>
 
-/* Register access macros */
-#define spi_readl(reg) _spi_readl(&SPI_##reg)
-#define spi_writel(reg,value) _spi_writel((value),&SPI_##reg)
+/***********************************************************************
+ * SPI register definitions
+ **********************************************************************/
+#define SPI_CONFIG_REG    0x00
+#define SPI_SLV_ENAB_REG  0x04
+#define SPI_TXF_FLUSH_REG 0x08
+#define SPI_FIFO_DATA_REG 0x0C
+#define SPI_NHP_POP_REG   0x10
+#define SPI_NHP_MODE_REG  0x14
+#define SPI_DMA_SET_REG   0x18
+#define SPI_STS_REG       0x1C
+#define SPI_HWINFO_REG    0x20
+#define SPI_SLV_SET1_REG(slv) (0x24 + (8 * slv))
+#define SPI_SLV_SET2_REG(slv) (0x28 + (8 * slv))
+#define SPI_INT_TRSH_REG  0xFD4
+#define SPI_INT_CLRE_REG  0xFD8
+#define SPI_INT_SETE_REG  0xFDC
+#define SPI_INT_STS_REG   0xFE0
+#define SPI_INT_ENAB_REG  0xFE4
+#define SPI_INT_CLRS_REG  0xFE8
+#define SPI_INT_SETS_REG  0xFEC
+#define SPI_MOD_ID_REG    0xFFC
+
+/* SPI device contants */
+#define SPI_FIFO_DEPTH  64 /* 64 words (16bit) deep */
+#define SPI_NUM_SLAVES  3  /* number of slaves supported */
+#define SPI_MAX_DIV2    254
+#define SPI_MAX_DIVIDER 65024 /* = 254 * (255 + 1) */
+#define SPI_MIN_DIVIDER 2
+
+/* SPI Configuration register definitions (SPI_CONFIG_REG) */
+#define SPI_CFG_INTER_DLY(n)      _SBF(16, ((n) & 0xFFFF))
+#define SPI_CFG_INTER_DLY_GET(n)  (((n) >> 16) & 0xFFFF)
+#define SPI_CFG_UPDATE_EN         _BIT(7)
+#define SPI_CFG_SW_RESET          _BIT(6)
+#define SPI_CFG_SLAVE_DISABLE     _BIT(4)
+#define SPI_CFG_MULTI_SLAVE       _BIT(3)
+#define SPI_CFG_LOOPBACK          _BIT(2)
+#define SPI_CFG_SLAVE_MODE        _BIT(1)
+#define SPI_CFG_ENABLE            _BIT(0)
+
+/* SPI slave_enable register definitions (SPI_SLV_ENAB_REG) */
+#define SPI_SLV_EN(n)             _SBF(((n) << 1), 0x1)
+#define SPI_SLV_SUSPEND(n)        _SBF(((n) << 1), 0x3)
+
+/* SPI tx_fifo_flush register definitions (SPI_TXF_FLUSH_REG) */
+#define SPI_TXFF_FLUSH            _BIT(0)
+
+/* SPI dma_settings register definitions (SPI_DMA_SET_REG) */
+#define SPI_DMA_TX_EN             _BIT(1)
+#define SPI_DMA_RX_EN             _BIT(0)
+
+/* SPI status register definitions (SPI_STS_REG) */
+#define SPI_ST_SMS_BUSY           _BIT(5)
+#define SPI_ST_BUSY               _BIT(4)
+#define SPI_ST_RX_FF              _BIT(3)
+#define SPI_ST_RX_EMPTY           _BIT(2)
+#define SPI_ST_TX_FF              _BIT(1)
+#define SPI_ST_TX_EMPTY           _BIT(0)
+
+/* SPI slv_setting registers definitions (SPI_SLV_SET1_REG) */
+#define SPI_SLV1_INTER_TX_DLY(n)  _SBF(24, ((n) & 0xFF))
+#define SPI_SLV1_NUM_WORDS(n)     _SBF(16, ((n) & 0xFF))
+#define SPI_SLV1_CLK_PS(n)        _SBF(8, ((n) & 0xFF))
+#define SPI_SLV1_CLK_PS_GET(n)    (((n) >> 8) & 0xFF)
+#define SPI_SLV1_CLK_DIV1(n)      ((n) & 0xFF)
+#define SPI_SLV1_CLK_DIV1_GET(n)  ((n) & 0xFF)
+
+/* SPI slv_setting registers definitions (SPI_SLV_SET2_REG) */
+#define SPI_SLV2_PPCS_DLY(n)      _SBF(9, ((n) & 0xFF))
+#define SPI_SLV2_CS_HIGH          _BIT(8)
+#define SPI_SLV2_SSI_MODE         _BIT(7)
+#define SPI_SLV2_SPO              _BIT(6)
+#define SPI_SLV2_SPH              _BIT(5)
+#define SPI_SLV2_WD_SZ(n)         ((n) & 0x1F)
+
+/* SPI int_threshold registers definitions (SPI_INT_TRSH_REG) */
+#define SPI_INT_TSHLD_TX(n)       _SBF(8, ((n) & 0xFF))
+#define SPI_INT_TSHLD_RX(n)       ((n) & 0xFF)
+
+/* SPI intterrupt registers definitions ( SPI_INT_xxx) */
+#define SPI_SMS_INT               _BIT(4)
+#define SPI_TX_INT                _BIT(3)
+#define SPI_RX_INT                _BIT(2)
+#define SPI_TO_INT                _BIT(1)
+#define SPI_OVR_INT               _BIT(0)
+#define SPI_ALL_INTS              (SPI_SMS_INT | SPI_TX_INT | SPI_RX_INT | SPI_TO_INT | SPI_OVR_INT)
+
+/* timeout in milliseconds */
+#define SPI_TIMEOUT		5
+
+
+/**
+ * struct lpc31xx_spi_chip - SPI device hardware settings
+ * @spi: back pointer to the SPI device
+ * @rate: max rate in hz this chip supports
+ * @div_cpsr: cpsr (pre-scaler) divider
+ * @div_scr: scr divider
+ * @dss: bits per word (4 - 16 bits)
+ * @ops: private chip operations
+ *
+ * This structure is used to store hardware register specific settings for each
+ * SPI device. Settings are written to hardware by function
+ * lpc31xx_spi_chip_setup().
+ */
+struct lpc31xx_spi_chip {
+	const struct spi_device *spi;
+	unsigned long	rate;
+	uint8_t		div_cpsr;
+	uint8_t		div_scr;
+	uint8_t		dss;
+	int 		gpio;
+	uint32_t	alow;
+};
+
+/**
+ * struct lpc31xx_spi - LPC31xx SPI controller structure
+ * @lock: spinlock that protects concurrent accesses to fields @running,
+ *        @current_msg and @msg_queue
+ * @pdev: pointer to platform device
+ * @clk: clock for the controller
+ * @regs_base: pointer to ioremap()'d registers
+ * @sspdr_phys: physical address of the SSPDR register
+ * @irq: IRQ number used by the driver
+ * @min_rate: minimum clock rate (in Hz) supported by the controller
+ * @max_rate: maximum clock rate (in Hz) supported by the controller
+ * @running: is the queue running
+ * @wq: workqueue used by the driver
+ * @msg_work: work that is queued for the driver
+ * @wait: wait here until given transfer is completed
+ * @msg_queue: queue for the messages
+ * @current_msg: message that is currently processed (or %NULL if none)
+ * @tx: current byte in transfer to transmit
+ * @rx: current byte in transfer to receive
+ * @fifo_level: how full is FIFO (%0..%SPI_FIFO_SIZE - %1). Receiving one
+ *              frame decreases this level and sending one frame increases it.
+ * @dma_rx: RX DMA channel
+ * @dma_tx: TX DMA channel
+ * @dma_rx_data: RX parameters passed to the DMA engine
+ * @dma_tx_data: TX parameters passed to the DMA engine
+ * @rx_sgt: sg table for RX transfers
+ * @tx_sgt: sg table for TX transfers
+ * @zeropage: dummy page used as RX buffer when only TX buffer is passed in by
+ *            the client
+ *
+ * This structure holds LPC31xx SPI controller specific information. When
+ * @running is %true, driver accepts transfer requests from protocol drivers.
+ * @current_msg is used to hold pointer to the message that is currently
+ * processed. If @current_msg is %NULL, it means that no processing is going
+ * on.
+ *
+ * Most of the fields are only written once and they can be accessed without
+ * taking the @lock. Fields that are accessed concurrently are: @current_msg,
+ * @running, and @msg_queue.
+ */
+struct lpc31xx_spi {
+	spinlock_t			lock;
+	const struct platform_device	*pdev;
+	struct clk			*clk;
+	void __iomem			*regs_base;
+	unsigned long			sspdr_phys;
+	int				irq;
+	unsigned long			min_rate;
+	unsigned long			max_rate;
+	bool				running;
+	struct workqueue_struct		*wq;
+	struct work_struct		msg_work;
+	struct completion		wait;
+	struct list_head		msg_queue;
+	struct spi_message		*current_msg;
+	size_t				tx;
+	size_t				rx;
+	size_t				fifo_level;
+	struct dma_chan			*dma_rx;
+	struct dma_chan			*dma_tx;
+	struct lpc31xx_dma_data		dma_rx_data;
+	struct lpc31xx_dma_data		dma_tx_data;
+	struct sg_table			rx_sgt;
+	struct sg_table			tx_sgt;
+	void				*zeropage;
+	uint32_t 			current_speed_hz;
+	uint8_t 			current_bits_wd;
+	struct lpc31xx_spi_chip		chips[];
+};
 
-static inline void _spi_writel(uint16_t value, volatile void *reg)
+static inline void
+lpc31xx_spi_write(const struct lpc31xx_spi *espi, uint32_t reg, uint32_t value)
 {
-	printk("spi_write %p value %x\n", reg, value);
-	__raw_writew(value, reg);
+	jds_printk("JDS - lpc31xx_spi_write %p value %x\n", espi->regs_base + reg, value);
+	__raw_writel(value, espi->regs_base + reg);
 }
 
-static inline uint16_t _spi_readl(volatile void *reg)
+static inline uint32_t
+lpc31xx_spi_read(const struct lpc31xx_spi *espi, uint32_t reg)
 {
-	uint16_t value;
-	value = __raw_readw(reg);
-	printk("spi_read %p value %x\n", reg, value);
+	uint32_t value;
+	value = __raw_readl(espi->regs_base + reg);
+	jds_printk("JDS - lpc31xx_spi_read %p value %x\n", espi->regs_base + reg, value);
 	return value;
 }
 
-struct lpc313xspi
+/*
+ * Clear a latched SPI interrupt
+ */
+static inline void lpc31xx_int_clr(const struct lpc31xx_spi *espi, uint32_t ints)
+{
+	lpc31xx_spi_write(espi, SPI_INT_CLRS_REG, ints);
+}
+
+/*
+ * Disable a SPI interrupt
+ */
+static inline void lpc31xx_int_dis(const struct lpc31xx_spi *espi, uint32_t ints)
 {
-	spinlock_t lock;
-	struct platform_device *pdev;
-	struct workqueue_struct	*workqueue;
-	struct work_struct work;
-	struct list_head queue;
-	wait_queue_head_t waitq;
-	struct spi_master *master;
-	int irq;
-	int id;
-	u32 spi_base_clock;
-	struct lpc313x_spi_cfg *psppcfg;
-	u32 current_speed_hz [3]; /* Per CS */
-	u8 current_bits_wd [3]; /* Per CS */
+	lpc31xx_spi_write(espi, SPI_INT_CLRE_REG, ints);
+}
 
-	/* DMA allocated regions */
-	u32 dma_base_v;
-	dma_addr_t dma_base_p;
+/*
+ * Set data width for the SPI chip select
+ */
+static void lpc31xx_set_cs_data_bits(struct lpc31xx_spi *espi, uint8_t data_width)
+{
+	jds_printk("JDS - lpc31xx_set_cs_data_bits, width %x\n", data_width);
+	if (espi->current_bits_wd != data_width)
+	{
+		uint32_t tmp = lpc31xx_spi_read(espi, SPI_SLV_SET2_REG(0));
+		tmp &= ~SPI_SLV2_WD_SZ(0x1F);
+		tmp |= SPI_SLV2_WD_SZ((uint32_t) (data_width - 1));
+		lpc31xx_spi_write(espi, SPI_SLV_SET2_REG(0), tmp);
 
-	/* DMA TX and RX physical and mapped spaces */
-	u32 dma_tx_base_v, dma_rx_base_v, dma_tx_base_p, dma_rx_base_p;
+		espi->current_bits_wd = data_width;
+	}
+}
 
-	/* Allocated DMA channels */
-	int tx_dma_ch, rx_dma_ch;
+/*
+ * Set clock rate and delays for the SPI chip select
+ */
+static void lpc31xx_set_cs_clock(struct lpc31xx_spi *espi, uint32_t clockrate)
+{
+	uint32_t reg, div, ps, div1;
 
-	/* DMA event flah */
-	volatile int rxdmaevent;
-};
+	jds_printk("JDS - lpc31xx_set_cs_clock\n");
+	if (clockrate != espi->current_speed_hz)
+	{
+		jds_printk("setting clock - lpc31xx_set_cs_clock\n");
+		reg = lpc31xx_spi_read(espi, SPI_SLV_SET1_REG(0));
+		reg &= ~0xFFFF;
+
+		div = ((espi->max_rate * 2)  + clockrate / 2) / clockrate;
+		if (div > SPI_MAX_DIVIDER)
+			div = SPI_MAX_DIVIDER;
+		if (div < SPI_MIN_DIVIDER)
+			div = SPI_MIN_DIVIDER;
+
+		ps = (((div - 1) / 512) + 1) * 2;
+		div1 = (((div + ps / 2) / ps) - 1);
+
+		lpc31xx_spi_write(espi, SPI_SLV_SET1_REG(0),
+			(reg | SPI_SLV1_CLK_PS(ps) | SPI_SLV1_CLK_DIV1(div1)));
+
+		espi->current_speed_hz = clockrate;
+	}
+}
 
 /*
  * Enable or disable the SPI clocks
  */
-static void lpc313x_spi_clks_enable(void)
+static void lpc31xx_spi_clks_enable(void)
 {
 	struct clk *clk;
 	int ret;
 
+	jds_printk("----clocks on-----------\n");
 	clk = clk_get(NULL, "spi_pclk");
 	ret = clk_enable(clk);
 	clk_put(clk);
@@ -117,10 +320,11 @@ static void lpc313x_spi_clks_enable(void)
 	clk_put(clk);
 }
 
-static void lpc313x_spi_clks_disable(void)
+static void lpc31xx_spi_clks_disable(void)
 {
 	struct clk *clk;
 
+	jds_printk("----clocks off-----------\n");
 	clk = clk_get(NULL, "spi_pclk");
 	clk_disable(clk);
 	clk_put(clk);
@@ -135,434 +339,582 @@ static void lpc313x_spi_clks_disable(void)
 	clk_put(clk);
 }
 
-/*
- * Flush the TX and RX FIFOs
- */
-static void lpc313x_fifo_flush(struct lpc313xspi *spidat)
+static int lpc31xx_spi_enable(const struct lpc31xx_spi *espi)
 {
-	volatile u32 tmp;
-
-	/* Clear TX FIFO first */
-	spi_writel(TXF_FLUSH_REG, SPI_TXFF_FLUSH);
+	jds_printk("JDS - lpc31xx_spi_enable\n");
+	lpc31xx_spi_clks_enable();
 
-	/* Clear RX FIFO */
-	while (!(spi_readl(STS_REG) & SPI_ST_RX_EMPTY))
-	{
-		tmp = spi_readl(FIFO_DATA_REG);
-	}
+	return 0;
 }
 
-/*
- * Clear a latched SPI interrupt
- */
-static inline void lpc313x_int_clr(struct lpc313xspi *spidat, u32 ints)
+static void lpc31xx_spi_disable(const struct lpc31xx_spi *espi)
 {
-	spi_writel(INT_CLRS_REG, ints);
+	jds_printk("JDS - lpc31xx_spi_disable\n");
+	lpc31xx_spi_clks_disable();
 }
 
-/*
- * Disable a SPI interrupt
- */
-static inline void lpc313x_int_dis(struct lpc313xspi *spidat, u32 ints)
+static void lpc31xx_spi_enable_interrupts(const struct lpc31xx_spi *espi)
 {
-	spi_writel(INT_CLRE_REG, ints);
+	jds_printk("JDS - lpc31xx_spi_enable_interrupts\n");
+	lpc31xx_spi_write(espi, SPI_INT_SETE_REG, (SPI_RX_INT | SPI_TO_INT | SPI_OVR_INT));
+	enable_irq(espi->irq);
+
+
+	jds_printk("int status %x\n", lpc31xx_spi_read(espi, SPI_INT_STS_REG));
 }
 
-/*
- * Enable a SPI interrupt
- */
-static inline void lpc313x_int_en(struct lpc313xspi *spidat, u32 ints)
+static void lpc31xx_spi_disable_interrupts(const struct lpc31xx_spi *espi)
 {
-	spi_writel(INT_SETE_REG, ints);
+	jds_printk("JDS - lpc31xx_spi_disable_interrupts\n");
+	disable_irq(espi->irq);
 }
 
-/*
- * Set a SPI chip select state
+/**
+ * lpc31xx_spi_calc_divisors() - calculates SPI clock divisors
+ * @espi: lpc31xx SPI controller struct
+ * @chip: divisors are calculated for this chip
+ * @rate: desired SPI output clock rate
+ *
+ * Function calculates cpsr (clock pre-scaler) and scr divisors based on
+ * given @rate and places them to @chip->div_cpsr and @chip->div_scr. If,
+ * for some reason, divisors cannot be calculated nothing is stored and
+ * %-EINVAL is returned.
  */
-static inline void spi_force_cs(struct lpc313xspi *spidat, u8 cs, uint cs_state)
+static int lpc31xx_spi_calc_divisors(const struct lpc31xx_spi *espi,
+				    struct lpc31xx_spi_chip *chip,
+				    unsigned long rate)
 {
-	spidat->psppcfg->spics_cfg[cs].spi_cs_set((int) cs, (int) cs_state);
+	unsigned long spi_clk_rate = clk_get_rate(espi->clk);
+	int cpsr, scr;
+
+	jds_printk("JDS - lpc31xx_spi_calc_divisors min %ld max %ld req %ld\n", espi->min_rate, espi->max_rate, rate);
+	/*
+	 * Make sure that max value is between values supported by the
+	 * controller. Note that minimum value is already checked in
+	 * lpc31xx_spi_transfer().
+	 */
+	rate = clamp(rate, espi->min_rate, espi->max_rate);
+
+	/*
+	 * Calculate divisors so that we can get speed according the
+	 * following formula:
+	 *	rate = spi_clock_rate / (cpsr * (1 + scr))
+	 *
+	 * cpsr must be even number and starts from 2, scr can be any number
+	 * between 0 and 255.
+	 */
+	for (cpsr = 2; cpsr <= 254; cpsr += 2) {
+		for (scr = 0; scr <= 255; scr++) {
+			if ((spi_clk_rate / (cpsr * (scr + 1))) <= rate) {
+				chip->div_scr = (uint8_t)scr;
+				chip->div_cpsr = (uint8_t)cpsr;
+				return 0;
+			}
+		}
+	}
+	return -EINVAL;
 }
 
-/*
- * Set data width for the SPI chip select
- */
-static void lpc313x_set_cs_data_bits(struct lpc313xspi *spidat, u8 cs, u8 data_width)
+static void lpc31xx_spi_cs_control(struct spi_device *spi, bool control)
 {
-	if (spidat->current_bits_wd[cs] != data_width)
-	{
-		u32 tmp = spi_readl(SLV_SET2_REG(0));
-		tmp &= ~SPI_SLV2_WD_SZ(0x1F);
-		tmp |= SPI_SLV2_WD_SZ((u32) (data_width - 1));
-		spi_writel(SLV_SET2_REG(0), tmp);
+	struct lpc31xx_spi_chip *chip = spi_get_ctldata(spi);
+	int value = (spi->mode & SPI_CS_HIGH) ? control : !control;
 
-		spidat->current_bits_wd[cs] = data_width;
-	}
+	if (!gpio_is_valid(chip->gpio))
+		return;
+	jds_printk("JDS - lpc31xx_spi_cs_control %d value %d\n", chip->gpio, value);
+	gpio_set_value(chip->gpio, value);
 }
 
-/*
- * Set clock rate and delays for the SPI chip select
+/**
+ * lpc31xx_spi_setup() - setup an SPI device
+ * @spi: SPI device to setup
+ *
+ * This function sets up SPI device mode, speed etc. Can be called multiple
+ * times for a single device. Returns 0 in case of success, negative error in
+ * case of failure. When this function returns success, the device is
+ * deselected.
  */
-static void lpc313x_set_cs_clock(struct lpc313xspi *spidat, u8 cs, u32 clockrate)
+static int lpc31xx_spi_setup(struct spi_device *spi)
 {
-	u32 reg, div, ps, div1;
+	struct lpc31xx_spi *espi = spi_master_get_devdata(spi->master);
+	struct lpc31xx_spi_chip *chip;
 
-	if (clockrate != spidat->current_speed_hz[cs])
-	{
-		reg = spi_readl(SLV_SET1_REG(0));
-		reg &= ~0xFFFF;
-
-		div = (spidat->spi_base_clock + clockrate / 2) / clockrate;
-		if (div > SPI_MAX_DIVIDER)
-			div = SPI_MAX_DIVIDER;
-		if (div < SPI_MIN_DIVIDER)
-			div = SPI_MIN_DIVIDER;
-
-		ps = (((div - 1) / 512) + 1) * 2;
-		div1 = (((div + ps / 2) / ps) - 1);
+	jds_printk("JDS - lpc31xx_spi_setup %s\n", spi->dev.of_node->full_name);
+	if (spi->bits_per_word < 4 || spi->bits_per_word > 16) {
+		dev_err(&espi->pdev->dev, "invalid bits per word %d\n",
+			spi->bits_per_word);
+		return -EINVAL;
+	}
 
-		spi_writel(SLV_SET1_REG(0),
-			(reg | SPI_SLV1_CLK_PS(ps) | SPI_SLV1_CLK_DIV1(div1)));
+	chip = spi_get_ctldata(spi);
+	if (!chip) {
+		dev_dbg(&espi->pdev->dev, "initial setup for %s\n",
+			spi->modalias);
 
-		spidat->current_speed_hz[cs] = clockrate;
+		if ((spi->chip_select < 0) || (spi->chip_select > spi->master->num_chipselect) ) {
+			dev_err(&espi->pdev->dev, "Invalid chip select reg, enough gpios?\n");
+			return -EINVAL;
+		}
+		chip = &espi->chips[spi->chip_select];
+		chip->spi = spi;
+		spi_set_ctldata(spi, chip);
+	}
+	if (spi->max_speed_hz != chip->rate) {
+		int err;
+
+		err = lpc31xx_spi_calc_divisors(espi, chip, spi->max_speed_hz);
+		jds_printk("spi calc err %d\n", err);
+		if (err != 0) {
+			spi_set_ctldata(spi, NULL);
+			return err;
+		}
+		chip->rate = spi->max_speed_hz;
+		jds_printk("spi max %d\n", spi->max_speed_hz);
 	}
+
+	lpc31xx_spi_cs_control(spi, false);
+	return 0;
 }
 
-/*
- * Setup the initial state of the SPI interface
+/**
+ * lpc31xx_spi_transfer() - queue message to be transferred
+ * @spi: target SPI device
+ * @msg: message to be transferred
+ *
+ * This function is called by SPI device drivers when they are going to transfer
+ * a new message. It simply puts the message in the queue and schedules
+ * workqueue to perform the actual transfer later on.
+ *
+ * Returns %0 on success and negative error in case of failure.
  */
-static void lpc313x_spi_prep(struct lpc313xspi *spidat)
+static int lpc31xx_spi_transfer(struct spi_device *spi, struct spi_message *msg)
 {
-	u32 tmp;
-
-	/* Reset SPI block */
-	spi_writel(CONFIG_REG, SPI_CFG_SW_RESET);
-
-	/* Clear FIFOs */
-	lpc313x_fifo_flush(spidat);
-
-	/* Clear latched interrupts */
-	lpc313x_int_dis(spidat, SPI_ALL_INTS);
-	lpc313x_int_clr(spidat, SPI_ALL_INTS);
-
-	/* Setup master mode, normal transmit mode, and interslave delay */
-	spi_writel(CONFIG_REG, SPI_CFG_INTER_DLY(1));
-
-	/* Make sure all 3 chip selects are initially disabled */
-	spi_writel(SLV_ENAB_REG, 0);
-	spi_writel(CONFIG_REG, (spi_readl(CONFIG_REG) | SPI_CFG_UPDATE_EN));
+	struct lpc31xx_spi *espi = spi_master_get_devdata(spi->master);
+	struct spi_transfer *t;
+	unsigned long flags;
 
-	/* FIFO trip points at 50% */
-	spi_writel(INT_TRSH_REG, (SPI_INT_TSHLD_TX(0x20) | SPI_INT_TSHLD_RX(0x20)));
+	jds_printk("JDS - lpc31xx_spi_transfer\n");
+	if (!msg || !msg->complete)
+		return -EINVAL;
 
-	/* Only chip select 0 is used in this driver. However, the timings for this
-	   chip select effect transfer speed and need to be adjusted for each GPO
-	   based chip select. Use a default value to start with for now. */
-	/* Inter-transfer delay is 0 (not used) */
-	tmp = spi_readl(SLV_SET1_REG(0));
-	tmp &= ~SPI_SLV1_INTER_TX_DLY(0xFF);
-	spi_writel(SLV_SET1_REG(0), (tmp | SPI_SLV1_INTER_TX_DLY(0)));
+	/* first validate each transfer */
+	list_for_each_entry(t, &msg->transfers, transfer_list) {
+		if (t->bits_per_word) {
+			if (t->bits_per_word < 4 || t->bits_per_word > 16)
+				return -EINVAL;
+		}
+		if (t->speed_hz && t->speed_hz < espi->min_rate)
+				return -EINVAL;
 
-	/* Configure enabled chip select slave setting 2 */
-	tmp = SPI_SLV2_PPCS_DLY(0) | SPI_SLV2_CS_HIGH | SPI_SLV2_SPO;
-	spi_writel(SLV_SET2_REG(0), tmp);
+		dev_dbg(&spi->dev,
+			"  xfer %p: len %u tx %p/%08x rx %p/%08x DMAmapped=%d\n",
+			t, t->len, t->tx_buf, t->tx_dma,
+			t->rx_buf, t->rx_dma, msg->is_dma_mapped);
+	}
 
-	/* Use a default of 8 data bits and a 100K clock for now */
-	lpc313x_set_cs_data_bits(spidat, 0, 8);
-	lpc313x_set_cs_clock(spidat, 0, 100000);
+	/*
+	 * Now that we own the message, let's initialize it so that it is
+	 * suitable for us. We use @msg->status to signal whether there was
+	 * error in transfer and @msg->state is used to hold pointer to the
+	 * current transfer (or %NULL if no active current transfer).
+	 */
+	msg->state = NULL;
+	msg->status = 0;
+	msg->actual_length = 0;
+
+	spin_lock_irqsave(&espi->lock, flags);
+	if (!espi->running) {
+		spin_unlock_irqrestore(&espi->lock, flags);
+		return -ESHUTDOWN;
+	}
+	list_add_tail(&msg->queue, &espi->msg_queue);
+	queue_work(espi->wq, &espi->msg_work);
+	spin_unlock_irqrestore(&espi->lock, flags);
 
-	/* We'll always use CS0 for this driver. Since the chip select is generated
-	   by a GPO, it doesn't matter which one we use */
-	spi_writel(SLV_ENAB_REG, SPI_SLV_EN(0));
-	spi_writel(CONFIG_REG, (spi_readl(CONFIG_REG) | SPI_CFG_UPDATE_EN));
+	return 0;
+}
 
-	/* Controller stays disabled until a transfer occurs */
+/**
+ * lpc31xx_spi_cleanup() - cleans up master controller specific state
+ * @spi: SPI device to cleanup
+ *
+ * This function releases master controller specific state for given @spi
+ * device.
+ */
+static void lpc31xx_spi_cleanup(struct spi_device *spi)
+{
+	jds_printk("JDS - lpc31xx_spi_cleanup\n");
+	spi_set_ctldata(spi, NULL);
 }
 
-/*
- * Setup a SPI transfer
+/**
+ * lpc31xx_spi_chip_setup() - configures hardware according to given @chip
+ * @espi: lpc31xx SPI controller struct
+ * @chip: chip specific settings
+ *
+ * This function sets up the actual hardware registers with settings given in
+ * @chip. Note that no validation is done so make sure that callers validate
+ * settings before calling this.
  */
-static int lpc313x_spi_setup(struct spi_device *spi)
+static void lpc31xx_spi_chip_setup(const struct lpc31xx_spi *espi,
+				  const struct lpc31xx_spi_chip *chip)
 {
-	unsigned int bits = spi->bits_per_word;
+	jds_printk("JDS - lpc31xx_spi_chip_setup\n");
+#if 0
+	u16 cr0;
 
-	/* There really isn't anuthing to do in this function, so verify the
-	   parameters are correct for the transfer */
-	if (spi->chip_select > spi->master->num_chipselect)
-	{
-		dev_dbg(&spi->dev,
-			"setup: invalid chipselect %u (%u defined)\n",
-			spi->chip_select, spi->master->num_chipselect);
-		return -EINVAL;
-	}
+	cr0 = chip->div_scr << SSPCR0_SCR_SHIFT;
+	cr0 |= (chip->spi->mode & (SPI_CPHA|SPI_CPOL)) << SSPCR0_MODE_SHIFT;
+	cr0 |= chip->dss;
 
-	if (bits == 0)
-	{
-		bits = 8;
-	}
-	if ((bits < 4) || (bits > 16))
-	{
-		dev_dbg(&spi->dev,
-			"setup: invalid bits_per_word %u (8 to 16)\n", bits);
-		return -EINVAL;
-	}
+	dev_dbg(&espi->pdev->dev, "setup: mode %d, cpsr %d, scr %d, dss %d\n",
+		chip->spi->mode, chip->div_cpsr, chip->div_scr, chip->dss);
+	dev_dbg(&espi->pdev->dev, "setup: cr0 %#x", cr0);
 
-	return 0;
+	lpc31xx_spi_write_uint8_t(espi, SSPCPSR, chip->div_cpsr);
+	lpc31xx_spi_write_u16(espi, SSPCR0, cr0);
+#endif
 }
 
-/*
- * Handle the SPI interrupt
- */
-static irqreturn_t lpc313x_spi_irq(int irq, void *dev_id)
+static inline int bits_per_word(const struct lpc31xx_spi *espi)
 {
-	struct lpc313xspi *spidat = dev_id;
-
-	/* Disable interrupts for now, do not clear the interrupt states */
-	lpc313x_int_dis(spidat, SPI_ALL_INTS);
-	spidat->rxdmaevent = 1;
+	struct spi_message *msg = espi->current_msg;
+	struct spi_transfer *t = msg->state;
 
-	wake_up(&spidat->waitq);
+	return t->bits_per_word ? t->bits_per_word : msg->spi->bits_per_word;
+}
 
-	return IRQ_HANDLED;
+static void lpc31xx_do_write(struct lpc31xx_spi *espi, struct spi_transfer *t)
+{
+	uint32_t data = 0x5555;
+
+	if (bits_per_word(espi) > 8) {
+		if (t->tx_buf)
+			data = ((uint16_t *)t->tx_buf)[espi->tx];
+		espi->tx += sizeof(uint16_t);
+	} else {
+		if (t->tx_buf)
+			data = ((uint8_t *)t->tx_buf)[espi->tx];
+		espi->tx += sizeof(uint8_t);
+	}
+	lpc31xx_spi_write(espi, SPI_FIFO_DATA_REG, data);
+	jds_printk("JDS - lpc31xx_do_write data %x\n", data);
 }
 
-/*
- * SPI DMA TX callback
- */
-static void lpc313x_dma_tx_spi_irq(int ch, dma_irq_type_t dtype, void *handle)
+static void lpc31xx_do_read(struct lpc31xx_spi *espi, struct spi_transfer *t)
 {
-	/* Nothing really needs to be done with the DMA TX interrupt, all the work
-	   is done with RX, so just return and let the DMA handler clear it. The
-	   SPI will stall the clock if the TX FIFO becomes empty so there is no
-	   chance of some type of underflow. */
+	uint32_t data;
+
+
+	data = lpc31xx_spi_read(espi, SPI_FIFO_DATA_REG);
+	jds_printk("JDS - lpc31xx_do_read data %x\n", data);
+	/* The data can be tossed if there is no RX buffer */
+	if (bits_per_word(espi) > 8) {
+		if (t->rx_buf)
+			((uint16_t *)t->rx_buf)[espi->rx] = data;
+		espi->rx += sizeof(uint16_t);
+	} else {
+		if (t->rx_buf)
+			((uint8_t *)t->rx_buf)[espi->rx] = data;
+		espi->rx += sizeof(uint8_t);
+	}
 }
 
-/*
- * SPI DMA RX callback
+/**
+ * lpc31xx_spi_read_write() - perform next RX/TX transfer
+ * @espi: lpc31xx SPI controller struct
+ *
+ * This function transfers next bytes (or half-words) to/from RX/TX FIFOs. If
+ * called several times, the whole transfer will be completed. Returns
+ * %-EINPROGRESS when current transfer was not yet completed otherwise %0.
+ *
+ * When this function is finished, RX FIFO should be empty and TX FIFO should be
+ * full.
  */
-static void lpc313x_dma_rx_spi_irq(int ch, dma_irq_type_t dtype, void *handle)
+static int lpc31xx_spi_read_write(struct lpc31xx_spi *espi)
 {
-	struct lpc313xspi *spidat = (struct lpc313xspi *) handle;
+	struct spi_message *msg = espi->current_msg;
+	struct spi_transfer *t = msg->state;
 
-	if (dtype == DMA_IRQ_FINISHED)
-	{
-		/* Disable interrupts for now */
-		dma_set_irq_mask(spidat->rx_dma_ch, 1, 1);
+	jds_printk("JDS - lpc31xx_spi_read_write, length %d\n", t->len);
+	jds_printk("JDS - lpc31xx_spi_read_write, rx %d tx %d\n", espi->rx, espi->tx);
 
-		/* Flag event and wakeup */
-		spidat->rxdmaevent = 1;
-		wake_up(&spidat->waitq);
+	/* Set the FIFO trip level to the transfer size */
+	lpc31xx_spi_write(espi, SPI_INT_TRSH_REG, (SPI_INT_TSHLD_TX(0) |
+		SPI_INT_TSHLD_RX(t->len - 1)));
+	lpc31xx_spi_write(espi, SPI_DMA_SET_REG, 0);
+
+	/* read as long as RX FIFO has frames in it */
+	while (!(lpc31xx_spi_read(espi, SPI_STS_REG) & SPI_ST_RX_EMPTY)) {
+		lpc31xx_do_read(espi, t);
+		espi->fifo_level--;
 	}
-	else if (dtype == DMA_IRQS_ABORT)
-	{
-		/* DMA data abort - this is global for the entire DMA
-		   peripheral. Do nothing, as this might not be a
-		   error for this channel. */
+
+	/* write as long as TX FIFO has room */
+	while ((espi->fifo_level < SPI_FIFO_DEPTH) && (espi->tx < t->len)) {
+		lpc31xx_do_write(espi, t);
+		espi->fifo_level++;
 	}
+
+	jds_printk("JDS - lpc31xx_spi_read_write, rx %d tx %d tlen %d\n", espi->rx, espi->tx, t->len);
+	if (espi->rx == t->len)
+		return 0;
+
+	return -EINPROGRESS;
 }
 
-/*
- * Handle a DMA transfer
- */
-static int lpc313x_spi_dma_transfer(struct lpc313xspi *spidat, struct spi_transfer *t,
-					u8 bits_per_word, int dmamapped)
+static void lpc31xx_spi_pio_transfer(struct lpc31xx_spi *espi)
 {
-	dma_setup_t dmarx, dmatx;
-	int status = 0;
-	u32 src, dest, srcmapped = 0, destmapped = 0;
-	struct device *dev = &spidat->pdev->dev;
-
-	/* Set the FIFO trip level to the transfer size */
-	spi_writel(INT_TRSH_REG, (SPI_INT_TSHLD_TX(16) |
-		SPI_INT_TSHLD_RX(1)));
-	spi_writel(DMA_SET_REG, (SPI_DMA_TX_EN | SPI_DMA_RX_EN));
-	lpc313x_int_dis(spidat, SPI_ALL_INTS);
-	lpc313x_int_en(spidat, SPI_OVR_INT);
-
-	/* Setup transfer */
-	if (bits_per_word > 8)
-	{
-		dmarx.cfg = DMA_CFG_TX_HWORD | DMA_CFG_RD_SLV_NR(DMA_SLV_SPI_RX) |
-			DMA_CFG_WR_SLV_NR(0);
-		dmatx.cfg = DMA_CFG_TX_HWORD | DMA_CFG_RD_SLV_NR(0) |
-			DMA_CFG_WR_SLV_NR(DMA_SLV_SPI_TX);
+	/*
+	 * Now everything is set up for the current transfer. We prime the TX
+	 * FIFO, enable interrupts, and wait for the transfer to complete.
+	 */
+	jds_printk("JDS - lpc31xx_spi_pio_transfer\n");
+	if (lpc31xx_spi_read_write(espi)) {
+		lpc31xx_spi_enable_interrupts(espi);
+		jds_printk("JDS - lpc31xx_spi_pio_transfer - waiting\n");
+		wait_for_completion(&espi->wait);
+		jds_printk("JDS - lpc31xx_spi_pio_transfer - waiting done\n");
+		lpc31xx_spi_disable_interrupts(espi);
 	}
+	jds_printk("JDS - lpc31xx_spi_pio_transfer - exit\n");
+}
+
+/**
+ * lpc31xx_spi_dma_prepare() - prepares a DMA transfer
+ * @espi: lpc31xx SPI controller struct
+ * @dir: DMA transfer direction
+ *
+ * Function configures the DMA, maps the buffer and prepares the DMA
+ * descriptor. Returns a valid DMA descriptor in case of success and ERR_PTR
+ * in case of failure.
+ */
+static struct dma_async_tx_descriptor *
+lpc31xx_spi_dma_prepare(struct lpc31xx_spi *espi, enum dma_data_direction dir)
+{
+	struct spi_transfer *t = espi->current_msg->state;
+	struct dma_async_tx_descriptor *txd;
+	enum dma_slave_buswidth buswidth;
+	struct dma_slave_config conf;
+	enum dma_transfer_direction slave_dirn;
+	struct scatterlist *sg;
+	struct sg_table *sgt;
+	struct dma_chan *chan;
+	const void *buf, *pbuf;
+	size_t len = t->len;
+	int i, ret, nents;
+
+	jds_printk("JDS - lpc31xx_spi_dma_prepare\n");
+	if (bits_per_word(espi) > 8)
+		buswidth = DMA_SLAVE_BUSWIDTH_2_BYTES;
 	else
-	{
-		dmarx.cfg = DMA_CFG_TX_BYTE | DMA_CFG_RD_SLV_NR(DMA_SLV_SPI_RX) |
-			DMA_CFG_WR_SLV_NR(0);
-		dmatx.cfg = DMA_CFG_TX_BYTE | DMA_CFG_RD_SLV_NR(0) |
-			DMA_CFG_WR_SLV_NR(DMA_SLV_SPI_TX);
+		buswidth = DMA_SLAVE_BUSWIDTH_1_BYTE;
+
+	memset(&conf, 0, sizeof(conf));
+	conf.direction = dir;
+
+	if (dir == DMA_FROM_DEVICE) {
+		chan = espi->dma_rx;
+		buf = t->rx_buf;
+		sgt = &espi->rx_sgt;
+
+		conf.src_addr = espi->sspdr_phys;
+		conf.src_addr_width = buswidth;
+		slave_dirn = DMA_DEV_TO_MEM;
+	} else {
+		chan = espi->dma_tx;
+		buf = t->tx_buf;
+		sgt = &espi->tx_sgt;
+
+		conf.dst_addr = espi->sspdr_phys;
+		conf.dst_addr_width = buswidth;
+		slave_dirn = DMA_MEM_TO_DEV;
 	}
 
-	/* Determine the DMA source and destination addresses. If DMA buffers weren't
-	   passed to this handler, they need to be mapped */
-	if (dmamapped)
-	{
-		src = t->tx_dma;
-		dest = t->rx_dma;
-		if ((src == 0) && (dest == 0))
-		{
-			/* DMA mapped flag set, but not mapped */
-			status = -ENOMEM;
-			goto exit;
-		}
-
-		/* At least one of the DMA buffers are already mapped */
-		if (src == 0)
-		{
-			/* Use temporary buffer for TX */
-			src = spidat->dma_tx_base_p;
-		}
-		else
-		{
-			dest = spidat->dma_rx_base_p;
-		}
+	ret = dmaengine_slave_config(chan, &conf);
+	if (ret)
+		return ERR_PTR(ret);
+
+	/*
+	 * We need to split the transfer into PAGE_SIZE'd chunks. This is
+	 * because we are using @espi->zeropage to provide a zero RX buffer
+	 * for the TX transfers and we have only allocated one page for that.
+	 *
+	 * For performance reasons we allocate a new sg_table only when
+	 * needed. Otherwise we will re-use the current one. Eventually the
+	 * last sg_table is released in lpc31xx_spi_release_dma().
+	 */
+
+	nents = DIV_ROUND_UP(len, PAGE_SIZE);
+	if (nents != sgt->nents) {
+		sg_free_table(sgt);
+
+		ret = sg_alloc_table(sgt, nents, GFP_KERNEL);
+		if (ret)
+			return ERR_PTR(ret);
 	}
-	else
-	{
-		/* Does TX buffer need to be DMA mapped */
-		if (t->tx_buf == NULL)
-		{
-			/* Use the temporary buffer for this transfer */
-			src = spidat->dma_tx_base_p;
-		}
-		else
-		{
-			/* Map DMA buffer */
-			src = (u32) dma_map_single(dev, (void *) t->tx_buf,
-				t->len, DMA_TO_DEVICE);
-			if (dma_mapping_error(dev, src))
-			{
-				status = -ENOMEM;
-				goto exit;
-			}
 
-			srcmapped = src;
-		}
+	pbuf = buf;
+	for_each_sg(sgt->sgl, sg, sgt->nents, i) {
+		size_t bytes = min_t(size_t, len, PAGE_SIZE);
 
-		/* Does RX buffer need to be DMA mapped */
-		if (t->rx_buf == NULL)
-		{
-			/* Use the temporary buffer for this transfer */
-			dest = spidat->dma_rx_base_p;
+		if (buf) {
+			sg_set_page(sg, virt_to_page(pbuf), bytes,
+				    offset_in_page(pbuf));
+		} else {
+			sg_set_page(sg, virt_to_page(espi->zeropage),
+				    bytes, 0);
 		}
-		else
-		{
-			/* Map DMA buffer */
-			dest = (u32) dma_map_single(dev, (void *) t->rx_buf,
-				t->len, DMA_FROM_DEVICE);
-			if (dma_mapping_error(dev, dest))
-			{
-				status = -ENOMEM;
-				goto exit;
-			}
 
-			destmapped = dest;
-		}
+		pbuf += bytes;
+		len -= bytes;
 	}
 
-	/* Setup transfer data for DMA */
-	dmarx.trans_length = (t->len - 1);
-	dmarx.src_address = (SPI_PHYS + 0x0C);
-	dmarx.dest_address = dest;
-	dmatx.trans_length = (t->len - 1);
-	dmatx.src_address = src;
-	dmatx.dest_address = (SPI_PHYS + 0x0C);
+	if (WARN_ON(len)) {
+		dev_warn(&espi->pdev->dev, "len = %d expected 0!", len);
+		return ERR_PTR(-EINVAL);
+	}
 
-	/* Setup the channels */
-	dma_prog_channel(spidat->rx_dma_ch, &dmarx);
-	dma_prog_channel(spidat->tx_dma_ch, &dmatx);
+	nents = dma_map_sg(chan->device->dev, sgt->sgl, sgt->nents, dir);
+	if (!nents)
+		return ERR_PTR(-ENOMEM);
 
-	/* Make sure the completion interrupt is enabled for RX, TX disabled */
-	dma_set_irq_mask(spidat->rx_dma_ch, 1, 0);
-	dma_set_irq_mask(spidat->tx_dma_ch, 1, 1);
+	txd = chan->device->device_prep_slave_sg(chan, sgt->sgl, nents,
+						 slave_dirn, DMA_CTRL_ACK);
+	if (!txd) {
+		dma_unmap_sg(chan->device->dev, sgt->sgl, sgt->nents, dir);
+		return ERR_PTR(-ENOMEM);
+	}
+	return txd;
+}
 
-	/* Start the transfer */
-	spidat->rxdmaevent = 0;
-	dma_start_channel(spidat->rx_dma_ch);
-	dma_start_channel(spidat->tx_dma_ch);
+/**
+ * lpc31xx_spi_dma_finish() - finishes with a DMA transfer
+ * @espi: lpc31xx SPI controller struct
+ * @dir: DMA transfer direction
+ *
+ * Function finishes with the DMA transfer. After this, the DMA buffer is
+ * unmapped.
+ */
+static void lpc31xx_spi_dma_finish(struct lpc31xx_spi *espi,
+				  enum dma_transfer_direction dir)
+{
+	struct dma_chan *chan;
+	struct sg_table *sgt;
+
+	jds_printk("JDS - lpc31xx_spi_dma_finish\n");
+	if (dir == DMA_DEV_TO_MEM) {
+		chan = espi->dma_rx;
+		sgt = &espi->rx_sgt;
+	} else {
+		chan = espi->dma_tx;
+		sgt = &espi->tx_sgt;
+	}
 
-	/* Wait for DMA to complete */
-	wait_event_interruptible(spidat->waitq, spidat->rxdmaevent);
+	dma_unmap_sg(chan->device->dev, sgt->sgl, sgt->nents, dir);
+}
 
-exit:
-	dma_stop_channel(spidat->tx_dma_ch);
-	dma_stop_channel(spidat->rx_dma_ch);
+static void lpc31xx_spi_dma_callback(void *callback_param)
+{
+	jds_printk("JDS - lpc31xx_spi_dma_callback\n");
+	complete(callback_param);
+}
 
-	/* Unmap buffers */
-	if (srcmapped != 0)
-	{
-		dma_unmap_single(dev, srcmapped, t->len, DMA_TO_DEVICE);
+static void lpc31xx_spi_dma_transfer(struct lpc31xx_spi *espi)
+{
+	struct spi_message *msg = espi->current_msg;
+	struct dma_async_tx_descriptor *rxd, *txd;
+
+	jds_printk("JDS - lpc31xx_spi_dma_transfer\n");
+	rxd = lpc31xx_spi_dma_prepare(espi, DMA_DEV_TO_MEM);
+	if (IS_ERR(rxd)) {
+		dev_err(&espi->pdev->dev, "DMA RX failed: %ld\n", PTR_ERR(rxd));
+		msg->status = PTR_ERR(rxd);
+		return;
 	}
-	if (destmapped != 0)
-	{
-		dma_unmap_single(dev, destmapped, t->len, DMA_FROM_DEVICE);
+
+	txd = lpc31xx_spi_dma_prepare(espi, DMA_MEM_TO_DEV);
+	if (IS_ERR(txd)) {
+		lpc31xx_spi_dma_finish(espi, DMA_MEM_TO_DEV);
+		dev_err(&espi->pdev->dev, "DMA TX failed: %ld\n", PTR_ERR(rxd));
+		msg->status = PTR_ERR(txd);
+		return;
 	}
 
-	return status;
+	/* We are ready when RX is done */
+	rxd->callback = lpc31xx_spi_dma_callback;
+	rxd->callback_param = &espi->wait;
+
+	/* Now submit both descriptors and wait while they finish */
+	dmaengine_submit(rxd);
+	dmaengine_submit(txd);
+
+	dma_async_issue_pending(espi->dma_rx);
+	dma_async_issue_pending(espi->dma_tx);
+
+	wait_for_completion(&espi->wait);
+
+	lpc31xx_spi_dma_finish(espi, DMA_MEM_TO_DEV);
+	lpc31xx_spi_dma_finish(espi, DMA_DEV_TO_MEM);
 }
 
-/*
- * The bulk of the transfer work is done in this function. Based on the transfer
- * size, either FIFO (PIO) or DMA mode may be used.
+/**
+ * lpc31xx_spi_process_transfer() - processes one SPI transfer
+ * @espi: lpc31xx SPI controller struct
+ * @msg: current message
+ * @t: transfer to process
+ *
+ * This function processes one SPI transfer given in @t. Function waits until
+ * transfer is complete (may sleep) and updates @msg->status based on whether
+ * transfer was successfully processed or not.
  */
-static void lpc313x_work_one(struct lpc313xspi *spidat, struct spi_message *m)
+static void lpc31xx_spi_process_transfer(struct lpc31xx_spi *espi,
+					struct spi_message *msg,
+					struct spi_transfer *t)
 {
-	struct spi_device *spi = m->spi;
-	struct spi_transfer *t;
-	unsigned int wsize, cs_change = 1;
-	int status = 0;
-	unsigned long flags;
-	u32 tmp;
-
-	/* Enable SPI clock and interrupts */
-	spin_lock_irqsave(&spidat->lock, flags);
-	lpc313x_spi_clks_enable();
-	enable_irq(spidat->irq);
-
-	/* Make sure FIFO is flushed and clear any pending interrupts */
-	lpc313x_fifo_flush(spidat);
-	/* lpc313x_int_clr(spidat, SPI_ALL_INTS); ***fix from JPP*** */
-
-	/* Process each transfer in the message */
-	list_for_each_entry (t, &m->transfers, transfer_list) {
-		const void *txbuf = t->tx_buf;
-		void *rxbuf = t->rx_buf;
-		u32 data;
-		unsigned int rlen, tlen = t->len;
-		u32 speed_hz = t->speed_hz ? : spi->max_speed_hz;
-		u8 bits_per_word = t->bits_per_word ? : spi->bits_per_word;
-
-		/* Bits per word, data transfer size, and transfer counter */
-		bits_per_word = bits_per_word ? : 8;
-		wsize = bits_per_word >> 3;
-		rlen = tlen;
-
-		/* Setup the appropriate chip select */
-		lpc313x_set_cs_clock(spidat, spi->chip_select, speed_hz);
-		lpc313x_set_cs_data_bits(spidat, spi->chip_select, bits_per_word);
- 
-		/* Setup timing and levels before initial chip select */
-		tmp = spi_readl(SLV_SET2_REG(0)) & ~(SPI_SLV2_SPO | SPI_SLV2_SPH);
-		if (spidat->psppcfg->spics_cfg[spi->chip_select].spi_spo != 0)
-		{
-			/* Clock high between transfers */
-			tmp |= SPI_SLV2_SPO;
-		}
-		if (spidat->psppcfg->spics_cfg[spi->chip_select].spi_sph != 0)
-		{
-			/* Data captured on 2nd clock edge */
-			tmp |= SPI_SLV2_SPH;
+	uint32_t tmp;
+	struct lpc31xx_spi_chip *chip = spi_get_ctldata(msg->spi);
+
+	jds_printk("JDS - lpc31xx_spi_process_transfer, bus width %d, %d\n", t->bits_per_word, msg->spi->bits_per_word);
+	msg->state = t;
+
+	/*
+	 * Handle any transfer specific settings if needed. We use
+	 * temporary chip settings here and restore original later when
+	 * the transfer is finished.
+	 */
+	if (t->speed_hz || t->bits_per_word) {
+		struct lpc31xx_spi_chip tmp_chip = *chip;
+
+		if (t->speed_hz) {
+			int err;
+
+			err = lpc31xx_spi_calc_divisors(espi, &tmp_chip,
+						       t->speed_hz);
+			if (err) {
+				dev_err(&espi->pdev->dev,
+					"failed to adjust speed\n");
+				msg->status = err;
+				return;
+			}
 		}
-		spi_writel(SLV_SET2_REG(0), tmp);
+		lpc31xx_set_cs_data_bits(espi, t->bits_per_word);
+		lpc31xx_set_cs_clock(espi, t->speed_hz);
 
-		lpc313x_int_clr(spidat, SPI_ALL_INTS);  /****fix from JPP*** */
+		/* Setup timing and levels before initial chip select */
+		tmp = lpc31xx_spi_read(espi, SPI_SLV_SET2_REG(0)) & ~(SPI_SLV2_SPO | SPI_SLV2_SPH);
+		/* Clock high between transfers */
+#if 0
+		tmp |= SPI_SLV2_SPO;
+		/* Data captured on 2nd clock edge */
+		tmp |= SPI_SLV2_SPH;
+#endif
+		lpc31xx_spi_write(espi, SPI_SLV_SET2_REG(0), tmp);
 
-		/* Make sure FIFO is flushed, clear pending interrupts, DMA
-		   initially disabled, and then enable SPI interface */
-		spi_writel(CONFIG_REG, (spi_readl(CONFIG_REG) | SPI_CFG_ENABLE));
+		lpc31xx_int_clr(espi, SPI_ALL_INTS);  /****fix from JPP*** */
 
+#if 0
 		/* Assert selected chip select */
 		if (cs_change)
 		{
@@ -570,461 +922,583 @@ static void lpc313x_work_one(struct lpc313xspi *spidat, struct spi_message *m)
 			spi_force_cs(spidat, spi->chip_select, 0);
 		}
 		cs_change = t->cs_change;
+#endif
+		/*
+		 * Set up temporary new hw settings for this transfer.
+		 */
+		lpc31xx_spi_chip_setup(espi, &tmp_chip);
+	}
+	/* Make sure FIFO is flushed, clear pending interrupts, DMA
+	   initially disabled, and then enable SPI interface */
+	lpc31xx_spi_write(espi, SPI_CONFIG_REG, (lpc31xx_spi_read(espi, SPI_CONFIG_REG) | SPI_CFG_ENABLE));
+
+	espi->rx = 0;
+	espi->tx = 0;
+
+	/*
+	 * There is no point of setting up DMA for the transfers which will
+	 * fit into the FIFO and can be transferred with a single interrupt.
+	 * So in these cases we will be using PIO and don't bother for DMA.
+	 */
+	if (espi->dma_rx && t->len > SPI_FIFO_DEPTH)
+		lpc31xx_spi_dma_transfer(espi);
+	else
+		lpc31xx_spi_pio_transfer(espi);
+
+	/*
+	 * In case of error during transmit, we bail out from processing
+	 * the message.
+	 */
+	if (msg->status)
+		return;
+
+	msg->actual_length += t->len;
+
+	/*
+	 * After this transfer is finished, perform any possible
+	 * post-transfer actions requested by the protocol driver.
+	 */
+	if (t->delay_usecs) {
+		set_current_state(TASK_UNINTERRUPTIBLE);
+		schedule_timeout(usecs_to_jiffies(t->delay_usecs));
+	}
+	if (t->cs_change) {
+		if (!list_is_last(&t->transfer_list, &msg->transfers)) {
+			/*
+			 * In case protocol driver is asking us to drop the
+			 * chip select briefly, we let the scheduler to handle
+			 * any "delay" here.
+			 */
+			lpc31xx_spi_cs_control(msg->spi, false);
+			cond_resched();
+			lpc31xx_spi_cs_control(msg->spi, true);
+		}
+	}
 
-		/* The driver will pick the best transfer method based on the
-		   current transfer size. For sizes smaller than the FIFO depth,
-		   the FIFOs are used without DMA support. For transfers larger
-		   than the FIFO depth, DMA is used. When dealing with fast SPI
-		   clock rates and transfers larger than the FIFO depth, DMA is
-		   required. The higher level SPI functions will limit transfer
-		   sizes to 4Kbytes. */
-		/***Fix from JPP ******/
-		/*if (tlen < (SPI_FIFO_DEPTH * wsize)) {*/
-		if (0) { //***MOD: Non-DMA SPI code broken -> possibly off-by-one bit error.
-			if ((txbuf == NULL) && (rxbuf == NULL))
-			{
-				/* A PIO mode DMA transfer requires mapped
-				   memory. Something is wrong. DMA transfer? */
-				dev_err(&spidat->pdev->dev, "No mapped buffers\n");
-				status = -EIO;
-				goto exit;
-			}
+	if (t->speed_hz || t->bits_per_word)
+		lpc31xx_spi_chip_setup(espi, chip);
+}
 
-			/* Set the FIFO trip level to the transfer size */
-			spi_writel(INT_TRSH_REG, (SPI_INT_TSHLD_TX(0) |
-				SPI_INT_TSHLD_RX(tlen - 1)));
-			spi_writel(DMA_SET_REG, 0);
-
-			/* Fill TX FIFO */
-			while ((!(spi_readl(STS_REG) & SPI_ST_TX_FF)) && (tlen > 0))
-			{
-				/* Fill FIFO */
-				if (txbuf)
-			{
-					data = (wsize == 1)
-						? *(const u8 *) txbuf
-						: *(const u16 *) txbuf;
-					spi_writel(FIFO_DATA_REG, data);
-					txbuf += wsize;
-				}
-				else
-				{
-					/* Send dummy data */
-					spi_writel(FIFO_DATA_REG, 0xFFFF);
-				}
-
-				tlen--;
-			}
+/*
+ * Flush the TX and RX FIFOs
+ */
+static int lpc313x_fifo_flush(struct lpc31xx_spi *espi)
+{
+	unsigned long timeout;
+	volatile uint32_t tmp;
 
-			/* Wait for data */
-			lpc313x_int_en(spidat, (SPI_RX_INT | SPI_TO_INT | SPI_OVR_INT));
-			spin_unlock_irqrestore(&spidat->lock, flags);
-			wait_event_interruptible(spidat->waitq,
-				(spi_readl(INT_STS_REG) & (SPI_RX_INT | SPI_OVR_INT)));
-			spin_lock_irqsave(&spidat->lock, flags);
-
-			/* Has an overflow occurred? */
-			if (unlikely(spi_readl(INT_STS_REG) & SPI_OVR_INT))
-			{
-				/* RX FIFO overflow */
-				dev_err(&spidat->pdev->dev, "RX FIFO overflow.\n");
-				status = -EIO;
-				goto exit;
-			}
+	/* Clear TX FIFO first */
+	lpc31xx_spi_write(espi, SPI_TXF_FLUSH_REG, SPI_TXFF_FLUSH);
 
-			/* Is there any data to read? */
-			while (!(spi_readl(STS_REG) & SPI_ST_RX_EMPTY))
-			{
-				data = spi_readl(FIFO_DATA_REG);
-				/* The data can be tossed if there is no RX buffer */
-				if (rxbuf)
-				{
-					if (wsize == 1)
-					{
-						*(u8 *)rxbuf = (u8) data;
-					}
-					else
-					{
-						*(u16 *)rxbuf = (u16) data;
-					}
-
-					rxbuf += wsize;
-				}
-
-				rlen--;
-			}
-		}
-		else {
-			/* DMA will be used for the transfer */
-			spin_unlock_irqrestore(&spidat->lock, flags);
-			status = lpc313x_spi_dma_transfer(spidat, t, bits_per_word,
-				m->is_dma_mapped);
-			spin_lock_irqsave(&spidat->lock, flags);
-			if (status < 0)
-				goto exit;
+	/* Clear RX FIFO */
+	timeout = jiffies + msecs_to_jiffies(SPI_TIMEOUT);
+	while (!(lpc31xx_spi_read(espi, SPI_STS_REG) & SPI_ST_RX_EMPTY)) {
+		if (time_after(jiffies, timeout)) {
+			dev_warn(&espi->pdev->dev,
+				 "timeout while flushing RX FIFO\n");
+			return -ETIMEDOUT;
 		}
+		tmp = lpc31xx_spi_read(espi, SPI_FIFO_DATA_REG);
+	}
+	return 0;
+}
 
-		m->actual_length += t->len;
-		if (t->delay_usecs)
-		{
-			udelay(t->delay_usecs);
-		}
+/*
+ * lpc31xx_spi_process_message() - process one SPI message
+ * @espi: lpc31xx SPI controller struct
+ * @msg: message to process
+ *
+ * This function processes a single SPI message. We go through all transfers in
+ * the message and pass them to lpc31xx_spi_process_transfer(). Chipselect is
+ * asserted during the whole message (unless per transfer cs_change is set).
+ *
+ * @msg->status contains %0 in case of success or negative error code in case of
+ * failure.
+ */
+static void lpc31xx_spi_process_message(struct lpc31xx_spi *espi,
+				       struct spi_message *msg)
+{
+	struct spi_transfer *t;
+	int err;
+
+	jds_printk("JDS - lpc31xx_spi_process_message\n");
+	/*
+	 * Enable the SPI controller and its clock.
+	 */
+	err = lpc31xx_spi_enable(espi);
+	if (err) {
+		dev_err(&espi->pdev->dev, "failed to enable SPI controller\n");
+		msg->status = err;
+		return;
+	}
+	err = lpc313x_fifo_flush(espi);
+	if (err)
+		return;
+	/*
+	 * We explicitly handle FIFO level. This way we don't have to check TX
+	 * FIFO status using %SSPSR_TNF bit which may cause RX FIFO overruns.
+	 */
+	espi->fifo_level = 0;
+
+	/*
+	 * Update SPI controller registers according to SPI device and assert
+	 * the chip select.
+	 */
+	lpc31xx_spi_chip_setup(espi, spi_get_ctldata(msg->spi));
+	lpc31xx_spi_cs_control(msg->spi, true);
+
+	list_for_each_entry(t, &msg->transfers, transfer_list) {
+		lpc31xx_spi_process_transfer(espi, msg, t);
+		if (msg->status)
+			break;
+	}
+
+	/*
+	 * Now the whole message is transferred (or failed for some reason). We
+	 * deselect the device and disable the SPI controller.
+	 */
+	lpc31xx_spi_cs_control(msg->spi, false);
+	lpc31xx_spi_disable(espi);
+}
 
-		if (!cs_change)
-			continue;
+#define work_to_espi(work) (container_of((work), struct lpc31xx_spi, msg_work))
 
-		if (t->transfer_list.next == &m->transfers)
-			break;
+/**
+ * lpc31xx_spi_work() - LPC31xx SPI workqueue worker function
+ * @work: work struct
+ *
+ * Workqueue worker function. This function is called when there are new
+ * SPI messages to be processed. Message is taken out from the queue and then
+ * passed to lpc31xx_spi_process_message().
+ *
+ * After message is transferred, protocol driver is notified by calling
+ * @msg->complete(). In case of error, @msg->status is set to negative error
+ * number, otherwise it contains zero (and @msg->actual_length is updated).
+ */
+static void lpc31xx_spi_work(struct work_struct *work)
+{
+	struct lpc31xx_spi *espi = work_to_espi(work);
+	struct spi_message *msg;
+
+	jds_printk("JDS - lpc31xx_spi_work\n");
+	spin_lock_irq(&espi->lock);
+	if (!espi->running || espi->current_msg ||
+		list_empty(&espi->msg_queue)) {
+		spin_unlock_irq(&espi->lock);
+		return;
 	}
+	msg = list_first_entry(&espi->msg_queue, struct spi_message, queue);
+	list_del_init(&msg->queue);
+	espi->current_msg = msg;
+	spin_unlock_irq(&espi->lock);
+
+	lpc31xx_spi_process_message(espi, msg);
+
+	/*
+	 * Update the current message and re-schedule ourselves if there are
+	 * more messages in the queue.
+	 */
+	spin_lock_irq(&espi->lock);
+	espi->current_msg = NULL;
+	if (espi->running && !list_empty(&espi->msg_queue))
+		queue_work(espi->wq, &espi->msg_work);
+	spin_unlock_irq(&espi->lock);
+
+	/* notify the protocol driver that we are done with this message */
+	msg->complete(msg->context);
+}
 
-exit:
-	if (!(status == 0 && cs_change))
+static irqreturn_t lpc31xx_spi_interrupt(int irq, void *dev_id)
+{
+	struct lpc31xx_spi *espi = dev_id;
+	jds_printk("JDS - lpc31xx_spi_interrupt\n");
+#if 0
+	uint8_t irq_status = lpc31xx_spi_read_uint8_t(espi, SSPIIR);
+
+	/*
+	 * If we got ROR (receive overrun) interrupt we know that something is
+	 * wrong. Just abort the message.
+	 */
+	if (unlikely(irq_status & SSPIIR_RORIS)) {
+		/* clear the overrun interrupt */
+		lpc31xx_spi_write_uint8_t(espi, SSPICR, 0);
+		dev_warn(&espi->pdev->dev,
+			 "receive overrun, aborting the message\n");
+		espi->current_msg->status = -EIO;
+	} else
+#endif
 	{
-		spi_force_cs(spidat, spi->chip_select, 1);
+		/*
+		 * Interrupt is either RX (RIS) or TX (TIS). For both cases we
+		 * simply execute next data transfer.
+		 */
+		if (lpc31xx_spi_read_write(espi)) {
+			/*
+			 * In normal case, there still is some processing left
+			 * for current transfer. Let's wait for the next
+			 * interrupt then.
+			 */
+			return IRQ_HANDLED;
+		}
 	}
 
-	/* Disable SPI, stop SPI clock to save power */
-	spi_writel(CONFIG_REG, (spi_readl(CONFIG_REG) & ~SPI_CFG_ENABLE));
-	disable_irq(spidat->irq);
-	lpc313x_spi_clks_disable();
+	/*
+	 * Current transfer is finished, either with error or with success. In
+	 * any case we disable interrupts and notify the worker to handle
+	 * any post-processing of the message.
+	 */
+	jds_printk("irq disable interrupt\n");
+	lpc31xx_int_dis(espi, SPI_ALL_INTS);
+	lpc31xx_int_clr(espi, SPI_ALL_INTS);
+	jds_printk("irq completing wait\n");
+	complete(&espi->wait);
+	return IRQ_HANDLED;
+}
 
-	spin_unlock_irqrestore(&spidat->lock, flags);
-	m->status = status;
-	m->complete(m->context);
+static bool lpc31xx_spi_dma_filter(struct dma_chan *chan, void *filter_param)
+{
+	chan->private = filter_param;
+	return true;
 }
 
-/*
- * Work queue function
- */
-static void lpc313x_work(struct work_struct *work)
+static int lpc31xx_spi_setup_dma(struct lpc31xx_spi *espi)
 {
-	struct lpc313xspi *spidat = container_of(work, struct lpc313xspi, work);
-	unsigned long flags;
+	dma_cap_mask_t mask;
+	int ret;
 
-	spin_lock_irqsave(&spidat->lock, flags);
+	jds_printk("JDS - lpc31xx_spi_setup_dma\n");
+	espi->zeropage = (void *)get_zeroed_page(GFP_KERNEL);
+	if (!espi->zeropage)
+		return -ENOMEM;
 
-	while (!list_empty(&spidat->queue))
-	{
-		struct spi_message *m;
+	dma_cap_zero(mask);
+	dma_cap_set(DMA_SLAVE, mask);
+
+#if 0
+	espi->dma_rx_data.port = EP93XX_DMA_SSP;
+#endif
+	espi->dma_rx_data.direction = DMA_DEV_TO_MEM;
+	espi->dma_rx_data.name = "lpc31xx-spi-rx";
 
-		m = container_of(spidat->queue.next, struct spi_message, queue);
-		list_del_init(&m->queue);
+	espi->dma_rx = dma_request_channel(mask, lpc31xx_spi_dma_filter,
+					   &espi->dma_rx_data);
+	if (!espi->dma_rx) {
+		ret = -ENODEV;
+		goto fail_free_page;
+	}
+
+#if 0
+	espi->dma_tx_data.port = EP93XX_DMA_SSP;
+#endif
+	espi->dma_tx_data.direction = DMA_MEM_TO_DEV;
+	espi->dma_tx_data.name = "lpc31xx-spi-tx";
 
-		spin_unlock_irqrestore(&spidat->lock, flags);
-		lpc313x_work_one(spidat, m);
-		spin_lock_irqsave(&spidat->lock, flags);
+	espi->dma_tx = dma_request_channel(mask, lpc31xx_spi_dma_filter,
+					   &espi->dma_tx_data);
+	if (!espi->dma_tx) {
+		ret = -ENODEV;
+		goto fail_release_rx;
 	}
 
-	spin_unlock_irqrestore(&spidat->lock, flags);
+	return 0;
+
+fail_release_rx:
+	dma_release_channel(espi->dma_rx);
+	espi->dma_rx = NULL;
+fail_free_page:
+	free_page((unsigned long)espi->zeropage);
+
+	return ret;
+}
+
+static void lpc31xx_spi_release_dma(struct lpc31xx_spi *espi)
+{
+	jds_printk("JDS - lpc31xx_spi_release_dma\n");
+	if (espi->dma_rx) {
+		dma_release_channel(espi->dma_rx);
+		sg_free_table(&espi->rx_sgt);
+	}
+	if (espi->dma_tx) {
+		dma_release_channel(espi->dma_tx);
+		sg_free_table(&espi->tx_sgt);
+	}
+
+	if (espi->zeropage)
+		free_page((unsigned long)espi->zeropage);
 }
 
 /*
- * Kick off a SPI transfer
+ * Setup the initial state of the SPI interface
  */
-static int lpc313x_spi_transfer(struct spi_device *spi, struct spi_message *m)
+static void lpc31xx_spi_prep(struct lpc31xx_spi *espi)
 {
-	struct spi_master *master = spi->master;
-	struct lpc313xspi *spidat = spi_master_get_devdata(master);
-	struct device *controller = spi->master->dev.parent;
-	struct spi_transfer *t;
-	unsigned long flags;
+	uint32_t tmp;
 
-	m->actual_length = 0;
+	jds_printk("JDS - lpc313x_spi_prep\n");
+	/* Reset SPI block */
+	lpc31xx_spi_write(espi, SPI_CONFIG_REG, SPI_CFG_SW_RESET);
 
-	/* check each transfer's parameters */
-	list_for_each_entry (t, &m->transfers, transfer_list)
-	{
-		u8 bits_per_word = t->bits_per_word ? : spi->bits_per_word;
+	/* Clear FIFOs */
+	lpc313x_fifo_flush(espi);
 
-		bits_per_word = bits_per_word ? : 8;
-		if ((!t->tx_buf) && (!t->rx_buf) && (t->len))
-		{
-			return -EINVAL;
-		}
-		if ((bits_per_word < 4) || (bits_per_word > 16))
-		{
-			return -EINVAL;
-		}
+	/* Clear latched interrupts */
+	lpc31xx_int_dis(espi, SPI_ALL_INTS);
+	lpc31xx_int_clr(espi, SPI_ALL_INTS);
 
-		dev_dbg(controller,
-			"  xfer %p: len %u tx %p/%08x rx %p/%08x DMAmapped=%d\n",
-			t, t->len, t->tx_buf, t->tx_dma,
-			t->rx_buf, t->rx_dma, m->is_dma_mapped);
-	}
+	/* Setup master mode, normal transmit mode, and interslave delay */
+	lpc31xx_spi_write(espi, SPI_CONFIG_REG, SPI_CFG_INTER_DLY(1));
 
-	spin_lock_irqsave(&spidat->lock, flags);
-	list_add_tail(&m->queue, &spidat->queue);
-	queue_work(spidat->workqueue, &spidat->work);
-	spin_unlock_irqrestore(&spidat->lock, flags);
+	/* Make sure all 3 chip selects are initially disabled */
+	lpc31xx_spi_write(espi, SPI_SLV_ENAB_REG, 0);
+	lpc31xx_spi_write(espi, SPI_CONFIG_REG, (lpc31xx_spi_read(espi, SPI_CONFIG_REG) | SPI_CFG_UPDATE_EN));
 
-	return 0;
-}
+	/* FIFO trip points at 50% */
+	lpc31xx_spi_write(espi, SPI_INT_TRSH_REG, (SPI_INT_TSHLD_TX(0x20) | SPI_INT_TSHLD_RX(0x20)));
 
-#ifdef CONFIG_OF
-static void spi_set_cs0_state(int cs_num, int state)
-{
-	(void) cs_num;
-	lpc313x_gpio_set_value(GPIO_SPI_CS_OUT0, state);
-}
+	/* Only chip select 0 is used in this driver. However, the timings for this
+	   chip select effect transfer speed and need to be adjusted for each GPIO
+	   based chip select. Use a default value to start with for now. */
+	/* Inter-transfer delay is 0 (not used) */
+	tmp = lpc31xx_spi_read(espi, SPI_SLV_SET1_REG(0));
+	tmp &= ~SPI_SLV1_INTER_TX_DLY(0xFF);
+	lpc31xx_spi_write(espi, SPI_SLV_SET1_REG(0), (tmp | SPI_SLV1_INTER_TX_DLY(0)));
 
-static void spi_set_cs1_state(int cs_num, int state)
-{
-	(void) cs_num;
-printk("cs1 state %d\n", state);
-	lpc313x_gpio_set_value(GPIO_MUART_CTS_N, state);
-}
+	/* Configure enabled chip select slave setting 2 */
+	tmp = SPI_SLV2_PPCS_DLY(0) | SPI_SLV2_CS_HIGH | SPI_SLV2_SPO;
+	lpc31xx_spi_write(espi, SPI_SLV_SET2_REG(0), tmp);
 
-static void spi_set_cs2_state(int cs_num, int state)
-{
-printk("cs2 state %d\n", state);
-	(void) cs_num;
-	lpc313x_gpio_set_value(GPIO_MUART_RTS_N, state);
-}
+	/* Use a default of 8 data bits and a 100K clock for now */
+	lpc31xx_set_cs_data_bits(espi, 8);
+	lpc31xx_set_cs_clock(espi, 100000);
 
-struct lpc313x_spics_cfg lpc313x_stdspics_cfg[] =
-{
-	/* SPI CS0 */
-	[0] =
-	{
-		.spi_spo	= 0, /* Low clock between transfers */
-		.spi_sph	= 0, /* Data capture on first clock edge (high edge with spi_spo=0) */
-		.spi_cs_set	= spi_set_cs0_state,
-	},
-	[1] =
-	{
-		.spi_spo	= 0, /* Low clock between transfers */
-		.spi_sph	= 0, /* Data capture on first clofck edge (high edge with spi_spo=0) */
-		.spi_cs_set	= spi_set_cs1_state,
-	},
-	[2] =
-	{
-		.spi_spo	= 0, /* Low clock between transfers */
-		.spi_sph	= 1, /* Data capture on first clock edge (high edge with spi_spo=0) */
-		.spi_cs_set	= spi_set_cs2_state,
-	},
-};
+	/* We'll always use CS0 for this driver. Since the chip select is generated
+	   by a GPIO, it doesn't matter which one we use */
+	lpc31xx_spi_write(espi, SPI_SLV_ENAB_REG, SPI_SLV_EN(0));
+	lpc31xx_spi_write(espi, SPI_CONFIG_REG, (lpc31xx_spi_read(espi, SPI_CONFIG_REG) | SPI_CFG_UPDATE_EN));
 
-struct lpc313x_spi_cfg lpc313x_spidata =
-{
-	.num_cs			= ARRAY_SIZE(lpc313x_stdspics_cfg),
-	.spics_cfg		= lpc313x_stdspics_cfg,
-};
-#endif
+	/* Controller stays disabled until a transfer occurs */
+}
 
-/*
- * SPI driver probe
- */
-static int __init lpc313x_spi_probe(struct platform_device *pdev)
+static int __devinit lpc31xx_spi_probe(struct platform_device *pdev)
 {
 	struct spi_master *master;
-	struct lpc313xspi *spidat;
-	struct clk *clk;
-	int ret, irq, i;
-	dma_addr_t dma_handle;
+	struct lpc31xx_spi *espi;
+	struct lpc31xx_spi_chip *chip;
+	struct resource *res;
+	int i, ngpios, error;
+
+	jds_printk("JDS - lpc31xx_spi_probe\n");
+
+	ngpios = of_gpio_count(pdev->dev.of_node); /* always one even if no gpios */
+	master = spi_alloc_master(&pdev->dev, sizeof(*espi) + (sizeof(*chip) * min(ngpios, 1)));
+	if (!master) {
+		dev_err(&pdev->dev, "failed to allocate spi master\n");
+		return -ENOMEM;
+	}
+	master->setup = lpc31xx_spi_setup;
+	master->transfer = lpc31xx_spi_transfer;
+	master->cleanup = lpc31xx_spi_cleanup;
+	master->bus_num = pdev->id;
+	master->num_chipselect = SPI_NUM_SLAVES;
+	master->mode_bits = SPI_CPOL | SPI_CPHA | SPI_CS_HIGH;
+	master->dev.of_node = of_node_get(pdev->dev.of_node);
 
-	/* Get required resources */
-	irq = platform_get_irq(pdev, 0);
-	if ((irq < 0) | (irq >= NR_IRQS))
-	{
-		return -EBUSY;
+	platform_set_drvdata(pdev, master);
+
+	espi = spi_master_get_devdata(master);
+
+	espi->irq = platform_get_irq(pdev, 4);
+	if (espi->irq < 0) {
+		error = -EBUSY;
+		dev_err(&pdev->dev, "failed to get irq resources\n");
+		goto fail_put_clock;
 	}
 
-	master = spi_alloc_master(&pdev->dev, sizeof(struct lpc313xspi));
-	if (!master)
-	{
-		return -ENODEV;
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res) {
+		dev_err(&pdev->dev, "unable to get iomem resource\n");
+		error = -ENODEV;
+		goto fail_put_clock;
 	}
-	spidat = spi_master_get_devdata(master);
-	platform_set_drvdata(pdev, master);
 
-	/* Is a board specific configuration available? */
-	spidat->psppcfg = (struct lpc313x_spi_cfg *) pdev->dev.platform_data;
-#ifdef CONFIG_OF
-	spidat->psppcfg = &lpc313x_spidata;
-#endif
-	if (spidat->psppcfg == NULL)
-	{
-		/* No platform data, exit */
-		ret = -ENODEV;
-		goto errout;
+	res = request_mem_region(res->start, resource_size(res), pdev->name);
+	if (!res) {
+		dev_err(&pdev->dev, "unable to request iomem resources\n");
+		error = -EBUSY;
+		goto fail_put_clock;
 	}
-	if (spidat->psppcfg->num_cs < 1)
-	{
-		/* No chip selects supported in board structure, exit */
-		ret = -ENODEV;
-		goto errout;
+
+	espi->sspdr_phys = res->start;
+	espi->regs_base = ioremap(res->start, resource_size(res));
+	jds_printk("JDS - base %p phys %x\n", espi->regs_base , res->start);
+	if (!espi->regs_base) {
+		dev_err(&pdev->dev, "failed to map resources\n");
+		error = -ENODEV;
+		goto fail_free_mem;
 	}
-	for (i = 0; i < spidat->psppcfg->num_cs; i++)
-	{
-		if (spidat->psppcfg->spics_cfg[i].spi_cs_set == NULL)
-		{
-			/* Missing hardware CS control callback, exit */
-			ret = -ENODEV;
-			goto errout;
-		}
+
+	error = request_irq(espi->irq, lpc31xx_spi_interrupt, 0, "lpc31xx-spi", espi);
+	if (error) {
+		dev_err(&pdev->dev, "failed to request irq\n");
+		goto fail_unmap_regs;
 	}
+	disable_irq(espi->irq);
 
-	/* Save ID for this device */
-	spidat->pdev = pdev;
-	spidat->id = pdev->id;
-	spidat->irq = irq;
-	spin_lock_init(&spidat->lock);
-
-	INIT_WORK(&spidat->work, lpc313x_work);
-	INIT_LIST_HEAD(&spidat->queue);
-	init_waitqueue_head(&spidat->waitq);
-	spidat->workqueue = create_singlethread_workqueue(dev_name(master->dev.parent));	//***MOD:Fix from JPP to compile to latest versions of Linux
-	if (!spidat->workqueue)
-	{
-		ret = -ENOMEM;
-		goto errout;
+	if (lpc31xx_spi_setup_dma(espi))
+		dev_warn(&pdev->dev, "DMA setup failed. Falling back to PIO\n");
+
+	espi->wq = create_singlethread_workqueue("lpc31xx_spid");
+	if (!espi->wq) {
+		dev_err(&pdev->dev, "unable to create workqueue\n");
+		goto fail_free_dma;
 	}
+	INIT_WORK(&espi->msg_work, lpc31xx_spi_work);
+	INIT_LIST_HEAD(&espi->msg_queue);
+	espi->running = true;
 
 	/* Enable clocks */
-	lpc313x_spi_clks_enable();
+	lpc31xx_spi_clks_enable();
 	cgu_soft_reset_module(SPI_PNRES_APB_SOFT);
 	cgu_soft_reset_module(SPI_PNRES_IP_SOFT);
 
-	ret = request_irq(spidat->irq, lpc313x_spi_irq,
-		IRQF_DISABLED, "spiirq", spidat);
-	if (ret)
-	{
-		ret = -EBUSY;
-		goto errout2;
+	espi->clk = clk_get(NULL, "spi_clk");
+	if (IS_ERR(espi->clk)) {
+		dev_err(&pdev->dev, "unable to get spi clock\n");
+		error = PTR_ERR(espi->clk);
+		goto fail_release_master;
 	}
-	disable_irq(spidat->irq);
-
-	master->bus_num = spidat->id;
-	master->setup = lpc313x_spi_setup;
-	master->transfer = lpc313x_spi_transfer;
-	master->num_chipselect = spidat->psppcfg->num_cs;
-
-	/* Setup several work DMA buffers for dummy TX and RX data. These buffers just
-	   hold the temporary TX or RX data for the unused half of the transfer and have
-	   a size of 4K (the maximum size of a transfer) */
-	spidat->dma_base_v = (u32) dma_alloc_coherent(&pdev->dev, (4096 << 1),
-		&dma_handle, GFP_KERNEL);
-	if (spidat->dma_base_v == (u32) NULL)
-	{
-		dev_err(&pdev->dev, "error getting DMA region.\n");
-		ret = -ENOMEM;
-		goto errout3;
-	}
-	spidat->dma_base_p = dma_handle;;
+	/*
+	 * Calculate maximum and minimum supported clock rates
+	 * for the controller.
+	 */
+	espi->max_rate = clk_get_rate(espi->clk) / 2;
+	espi->min_rate = clk_get_rate(espi->clk) / (254 * 256);
+	espi->pdev = pdev;
 
-	spidat->dma_tx_base_p = (u32) spidat->dma_base_p;
-	spidat->dma_tx_base_v = spidat->dma_base_v;
-	spidat->dma_rx_base_p = (u32) spidat->dma_base_p + 4096;
-	spidat->dma_rx_base_v = spidat->dma_base_v + 4096;
+	lpc31xx_spi_prep(espi);
 
-	/* Fill dummy TX buffer with 0 */
-	memset((void *) spidat->dma_tx_base_v, 0, 4096);
+	/* Keep SPI clocks off until a transfer is performed to save power */
+	lpc31xx_spi_clks_disable();
 
-	/* Initial setup of SPI */
-	clk = clk_get(NULL, "spi_clk");
-	spidat->spi_base_clock = clk->get_rate(clk);
-	clk_put(clk);
-	lpc313x_spi_prep(spidat);
+	spin_lock_init(&espi->lock);
+	init_completion(&espi->wait);
 
-	/* Keep SPI clocks off until a transfer is performed to save power */
-	lpc313x_spi_clks_disable();
+	for (i = 0; i < ngpios; i++) {
+		int gpio;
+		enum of_gpio_flags flags;
 
-	/* Request RX and TX DMA channels */
-	spidat->tx_dma_ch = spidat->rx_dma_ch = -1;
-	spidat->tx_dma_ch = dma_request_channel("spi_tx", lpc313x_dma_tx_spi_irq, spidat);
-	if (spidat->tx_dma_ch < 0)
-	{
-		dev_err(&pdev->dev, "error getting TX DMA channel.\n");
-		ret = -EBUSY;
-		goto errout4;
-	}
-	spidat->rx_dma_ch = dma_request_channel("spi_rx", lpc313x_dma_rx_spi_irq, spidat);
-	if (spidat->rx_dma_ch < 0)
-	{
-		dev_err(&pdev->dev, "error getting RX DMA channel.\n");
-		ret = -EBUSY;
-		goto errout4;
+		gpio = of_get_gpio_flags(pdev->dev.of_node, i, &flags);
+		if (!gpio_is_valid(gpio)) {
+			dev_err(&pdev->dev, "invalid gpio #%d: %d\n", i, gpio);
+			error = gpio;
+			goto fail_free_queue;
+		}
+		error = gpio_request(gpio, dev_name(&pdev->dev));
+		if (error) {
+			dev_err(&pdev->dev, "can't request gpio #%d: %d\n", i, error);
+			goto fail_free_queue;
+		}
+		espi->chips[i].gpio = gpio;
+		espi->chips[i].alow = flags & OF_GPIO_ACTIVE_LOW;
+
+		error = gpio_direction_output(gpio, espi->chips[i].alow);
+		if (error) {
+			dev_err(&pdev->dev, "can't set output direction for gpio #%d: %d\n", i, error);
+			goto fail_free_queue;
+		}
 	}
-#ifdef CONFIG_OF
-	master->dev.of_node = of_node_get(pdev->dev.of_node);
-#endif
 
-	ret = spi_register_master(master);
-	if (ret)
-	{
-		goto errout4;
+	error = spi_register_master(master);
+	if (error) {
+		dev_err(&pdev->dev, "failed to register SPI master\n");
+		goto fail_free_queue;
 	}
 
-	dev_info(&pdev->dev, "LPC313x SPI driver\n");
+	dev_info(&pdev->dev, "LPC31xx SPI Controller at 0x%08lx irq %d\n",
+		 (unsigned long)res->start, espi->irq);
 
 	return 0;
 
-errout4:
-	if (spidat->tx_dma_ch != -1)
-		dma_release_channel(spidat->tx_dma_ch);
-	if (spidat->rx_dma_ch != -1)
-		dma_release_channel(spidat->rx_dma_ch);
-	dma_free_coherent(&pdev->dev, (4096 << 1), (void *) spidat->dma_base_v,
-		spidat->dma_base_p);
-errout3:
-	free_irq(spidat->irq, pdev);
-errout2:
-	lpc313x_spi_clks_disable();
-	destroy_workqueue(spidat->workqueue);
-errout:
-	platform_set_drvdata(pdev, NULL);
+fail_free_queue:
+	while (i >= 0) {
+		if (gpio_is_valid(espi->chips[i].gpio))
+			gpio_free(espi->chips[i].gpio);
+		i--;
+	}
+	destroy_workqueue(espi->wq);
+fail_free_dma:
+	lpc31xx_spi_release_dma(espi);
+	free_irq(espi->irq, espi);
+fail_unmap_regs:
+	iounmap(espi->regs_base);
+fail_free_mem:
+	release_mem_region(res->start, resource_size(res));
+fail_put_clock:
+	clk_put(espi->clk);
+fail_release_master:
 	spi_master_put(master);
+	platform_set_drvdata(pdev, NULL);
 
-	return ret;
+	return error;
 }
 
-/*
- * SPI driver removal
- */
-static int __devexit lpc313x_spi_remove(struct platform_device *pdev)
+static int __devexit lpc31xx_spi_remove(struct platform_device *pdev)
 {
-	struct spi_master *master = spi_master_get(platform_get_drvdata(pdev));
-	struct lpc313xspi *spidat = spi_master_get_devdata(master);
-
-	/* Disable SPI interface */
-	spi_writel(CONFIG_REG, (spi_readl(CONFIG_REG) & ~SPI_CFG_ENABLE));
-	lpc313x_spi_clks_disable();
-
-	spi_unregister_master(master);
+	struct spi_master *master = platform_get_drvdata(pdev);
+	struct lpc31xx_spi *espi = spi_master_get_devdata(master);
+	struct resource *res;
+
+	jds_printk("JDS - lpc31xx_spi_remove\n");
+	spin_lock_irq(&espi->lock);
+	espi->running = false;
+	spin_unlock_irq(&espi->lock);
+
+	destroy_workqueue(espi->wq);
+
+	/*
+	 * Complete remaining messages with %-ESHUTDOWN status.
+	 */
+	spin_lock_irq(&espi->lock);
+	while (!list_empty(&espi->msg_queue)) {
+		struct spi_message *msg;
+
+		msg = list_first_entry(&espi->msg_queue,
+				       struct spi_message, queue);
+		list_del_init(&msg->queue);
+		msg->status = -ESHUTDOWN;
+		spin_unlock_irq(&espi->lock);
+		msg->complete(msg->context);
+		spin_lock_irq(&espi->lock);
+	}
+	spin_unlock_irq(&espi->lock);
+
+	lpc31xx_spi_release_dma(espi);
+	free_irq(espi->irq, espi);
+	iounmap(espi->regs_base);
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	release_mem_region(res->start, resource_size(res));
+	clk_put(espi->clk);
 	platform_set_drvdata(pdev, NULL);
 
-	if (spidat->tx_dma_ch != -1)
-		dma_release_channel(spidat->tx_dma_ch);
-	if (spidat->rx_dma_ch != -1)
-		dma_release_channel(spidat->rx_dma_ch);
-
-	dma_free_coherent(&pdev->dev, (4096 << 1), (void *) spidat->dma_base_v,
-		spidat->dma_base_p);
-
-	/* Free resources */
-	free_irq(spidat->irq, pdev);
-
-	destroy_workqueue(spidat->workqueue);
-	spi_master_put(master);
-
+	spi_unregister_master(master);
 	return 0;
 }
 
 /**
  * Suspend SPI by switching off the IP clocks
  **/
-static int lpc313x_spi_suspend(struct platform_device *pdev, pm_message_t state)
+static int lpc31xx_spi_suspend(struct platform_device *pdev, pm_message_t state)
 {
 #ifdef CONFIG_PM
-	struct spi_master *master = spi_master_get(platform_get_drvdata(pdev));
-	struct lpc313xspi *spidat = spi_master_get_devdata(master);
+	struct spi_master *master = platform_get_drvdata(pdev);
+	struct lpc31xx_spi *espi = spi_master_get_devdata(master);
 
 	/* Check if SPI is idle before we pull off the clock */
-	if (unlikely(!list_empty(&spidat->queue)))
+	if (unlikely(!list_empty(&espi->msg_queue)))
 		return 0;
 
 	/* Pull the clocks off */
-	lpc313x_spi_clks_disable();
+	lpc31xx_spi_clks_disable();
 #endif
 	return 0;
 }
@@ -1032,14 +1506,14 @@ static int lpc313x_spi_suspend(struct platform_device *pdev, pm_message_t state)
 /**
  * Resume SPI by switching on the IP clocks
  **/
-static int lpc313x_spi_resume(struct platform_device *pdev)
+static int lpc31xx_spi_resume(struct platform_device *pdev)
 {
 #ifdef CONFIG_PM
-	struct spi_master *master = spi_master_get(platform_get_drvdata(pdev));
-	struct lpc313xspi *spidat = spi_master_get_devdata(master);
+	//struct spi_master *master = spi_master_get(platform_get_drvdata(pdev));
+	//struct lpc313xspi *spidat = spi_master_get_devdata(master);
 
 	/* Switch on the clocks */
-	lpc313x_spi_clks_enable();
+	lpc31xx_spi_clks_enable();
 #endif
 	return 0;
 }
@@ -1052,11 +1526,11 @@ static const struct of_device_id lpc313x_spi_of_match[] = {
 MODULE_DEVICE_TABLE(of, lpc313x_spi_of_match);
 #endif
 
-static struct platform_driver lpc313x_spi_driver = {
-	.probe		= lpc313x_spi_probe,
-	.remove		= __devexit_p(lpc313x_spi_remove),
-	.suspend    = lpc313x_spi_suspend,
-	.resume     = lpc313x_spi_resume,
+static struct platform_driver lpc31xx_spi_driver = {
+	.probe		= lpc31xx_spi_probe,
+	.remove		= __devexit_p(lpc31xx_spi_remove),
+	.suspend	= lpc31xx_spi_suspend,
+	.resume		= lpc31xx_spi_resume,
 	.driver		= {
 		.name	= "spi_lpc313x",
 		.owner	= THIS_MODULE,
@@ -1065,20 +1539,9 @@ static struct platform_driver lpc313x_spi_driver = {
 #endif
 	},
 };
+module_platform_driver(lpc31xx_spi_driver);
 
-static int __init lpc313x_spi_init(void)
-{
-	return platform_driver_register(&lpc313x_spi_driver);
-}
-
-static void __exit lpc313x_spi_exit(void)
-{
-	platform_driver_unregister(&lpc313x_spi_driver);
-}
-
-module_init(lpc313x_spi_init);
-module_exit(lpc313x_spi_exit);
-
-MODULE_AUTHOR("Kevin Wells <kevin.wells@nxp.com");
-MODULE_DESCRIPTION("LPC313X SPI Driver");
+MODULE_DESCRIPTION("LPC31xx SPI Controller driver");
+MODULE_AUTHOR("Jon Smirl <jonsmirl@gmail.com>");
 MODULE_LICENSE("GPL");
+MODULE_ALIAS("platform:lpc31xx-spi");
diff --git a/dt_config b/dt_config
index 5ac5df2..9a449e2 100644
--- a/dt_config
+++ b/dt_config
@@ -1126,7 +1126,7 @@ CONFIG_WATCHDOG=y
 # CONFIG_SOFT_WATCHDOG is not set
 # CONFIG_DW_WATCHDOG is not set
 # CONFIG_MAX63XX_WATCHDOG is not set
-CONFIG_LPC313X_WATCHDOG=y
+CONFIG_LPC31XX_WATCHDOG=y
 
 #
 # USB-based Watchdog Cards
